{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resolve paths from root project directory\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATE = \"16-dec\"\n",
    "DATA_DIR = \"../data/parsed-export/{}/\".format(DATE)\n",
    "EXPORT_DIR = \"../data/dataframes/{}/\".format(DATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_tools.dataframes import create_tweet_df, create_user_df, create_retweet_df, aggregate_counts_by_hour, aggregate_most_common_hashtags, create_media_df, group_df_by_hour\n",
    "from data_tools import load_crawled_terms "
   ]
  },
  {
   "source": [
    "## Load from cache"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retweet_df = pd.read_pickle(EXPORT_DIR + 'df_retweets.pickle')\n",
    "# df_users = pd.read_pickle(EXPORT_DIR + 'df_users.pickle')\n",
    "recent_tweet_df = pd.read_pickle(EXPORT_DIR + 'df_recent_tweets.pickle')"
   ]
  },
  {
   "source": [
    "## Build from scratch"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CRAWLED_TERMS = load_crawled_terms(\"../keywords-3nov.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ed-export/16-dec/parsed_retweets.json processed (0.3010721206665039 sec)\n",
      "(31%): 8000000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.30106377601623535 sec)\n",
      "(32%): 8100000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3253798484802246 sec)\n",
      "(32%): 8200000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3010692596435547 sec)\n",
      "(32%): 8300000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.30153942108154297 sec)\n",
      "(33%): 8400000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3006110191345215 sec)\n",
      "(33%): 8500000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.30153369903564453 sec)\n",
      "(34%): 8600000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.30160045623779297 sec)\n",
      "(34%): 8700000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3020591735839844 sec)\n",
      "(34%): 8800000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.30203700065612793 sec)\n",
      "(35%): 8900000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.30553531646728516 sec)\n",
      "(35%): 9000000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.30457425117492676 sec)\n",
      "(36%): 9100000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.33281993865966797 sec)\n",
      "(36%): 9200000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3050384521484375 sec)\n",
      "(36%): 9300000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3040163516998291 sec)\n",
      "(37%): 9400000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3045787811279297 sec)\n",
      "(37%): 9500000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.30404210090637207 sec)\n",
      "(38%): 9600000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.30553627014160156 sec)\n",
      "(38%): 9700000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3055379390716553 sec)\n",
      "(38%): 9800000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3045375347137451 sec)\n",
      "(39%): 9900000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.30501651763916016 sec)\n",
      "(39%): 10000000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.30208778381347656 sec)\n",
      "(40%): 10100000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.30306529998779297 sec)\n",
      "(40%): 10200000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3343043327331543 sec)\n",
      "(40%): 10300000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.31446361541748047 sec)\n",
      "(41%): 10400000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3070247173309326 sec)\n",
      "(41%): 10500000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3059978485107422 sec)\n",
      "(41%): 10600000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.30208897590637207 sec)\n",
      "(42%): 10700000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.30206799507141113 sec)\n",
      "(42%): 10800000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3025648593902588 sec)\n",
      "(43%): 10900000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3040480613708496 sec)\n",
      "(43%): 11000000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.301069974899292 sec)\n",
      "(43%): 11100000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.30156683921813965 sec)\n",
      "(44%): 11200000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.30306196212768555 sec)\n",
      "(44%): 11300000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.30252623558044434 sec)\n",
      "(45%): 11400000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3016026020050049 sec)\n",
      "(45%): 11500000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.33925962448120117 sec)\n",
      "(45%): 11600000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.30355191230773926 sec)\n",
      "(46%): 11700000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3035614490509033 sec)\n",
      "(46%): 11800000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3040459156036377 sec)\n",
      "(47%): 11900000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.30553603172302246 sec)\n",
      "(47%): 12000000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3050391674041748 sec)\n",
      "(47%): 12100000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3124735355377197 sec)\n",
      "(48%): 12200000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.30653929710388184 sec)\n",
      "(48%): 12300000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.31098151206970215 sec)\n",
      "(49%): 12400000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3164527416229248 sec)\n",
      "(49%): 12500000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.30652832984924316 sec)\n",
      "(49%): 12600000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3060321807861328 sec)\n",
      "(50%): 12700000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.30454587936401367 sec)\n",
      "(50%): 12800000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.30652689933776855 sec)\n",
      "(50%): 12900000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.34617066383361816 sec)\n",
      "(51%): 13000000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3050401210784912 sec)\n",
      "(51%): 13100000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.30209779739379883 sec)\n",
      "(52%): 13200000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3010721206665039 sec)\n",
      "(52%): 13300000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3015732765197754 sec)\n",
      "(52%): 13400000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.300570011138916 sec)\n",
      "(53%): 13500000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3109886646270752 sec)\n",
      "(53%): 13600000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3050425052642822 sec)\n",
      "(54%): 13700000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.307023286819458 sec)\n",
      "(54%): 13800000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.30600547790527344 sec)\n",
      "(54%): 13900000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3055572509765625 sec)\n",
      "(55%): 14000000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.30405497550964355 sec)\n",
      "(55%): 14100000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3020658493041992 sec)\n",
      "(56%): 14200000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.306499719619751 sec)\n",
      "(56%): 14300000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.301072359085083 sec)\n",
      "(56%): 14400000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3020925521850586 sec)\n",
      "(57%): 14500000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.30107879638671875 sec)\n",
      "(57%): 14600000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.35067224502563477 sec)\n",
      "(57%): 14700000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.2995483875274658 sec)\n",
      "(58%): 14800000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.30904555320739746 sec)\n",
      "(58%): 14900000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.30301952362060547 sec)\n",
      "(59%): 15000000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3030848503112793 sec)\n",
      "(59%): 15100000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3010435104370117 sec)\n",
      "(59%): 15200000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.30358099937438965 sec)\n",
      "(60%): 15300000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.29958343505859375 sec)\n",
      "(60%): 15400000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.29958415031433105 sec)\n",
      "(61%): 15500000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.29859399795532227 sec)\n",
      "(61%): 15600000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.30106568336486816 sec)\n",
      "(61%): 15700000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.2985959053039551 sec)\n",
      "(62%): 15800000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.30005311965942383 sec)\n",
      "(62%): 15900000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3030881881713867 sec)\n",
      "(63%): 16000000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.31347227096557617 sec)\n",
      "(63%): 16100000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3149540424346924 sec)\n",
      "(63%): 16200000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.31397461891174316 sec)\n",
      "(64%): 16300000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3020310401916504 sec)\n",
      "(64%): 16400000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3690516948699951 sec)\n",
      "(65%): 16500000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3035571575164795 sec)\n",
      "(65%): 16600000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.32338643074035645 sec)\n",
      "(65%): 16700000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.30699729919433594 sec)\n",
      "(66%): 16800000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3121001720428467 sec)\n",
      "(66%): 16900000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.31000852584838867 sec)\n",
      "(66%): 17000000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3079833984375 sec)\n",
      "(67%): 17100000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3090083599090576 sec)\n",
      "(67%): 17200000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3209500312805176 sec)\n",
      "(68%): 17300000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3080008029937744 sec)\n",
      "(68%): 17400000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3105015754699707 sec)\n",
      "(68%): 17500000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.30997180938720703 sec)\n",
      "(69%): 17600000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3040804862976074 sec)\n",
      "(69%): 17700000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3010725975036621 sec)\n",
      "(70%): 17800000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3060281276702881 sec)\n",
      "(70%): 17900000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3020639419555664 sec)\n",
      "(70%): 18000000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.30156850814819336 sec)\n",
      "(71%): 18100000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.30156803131103516 sec)\n",
      "(71%): 18200000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.30751729011535645 sec)\n",
      "(72%): 18300000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.30156683921813965 sec)\n",
      "(72%): 18400000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.35910964012145996 sec)\n",
      "(72%): 18500000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.30354762077331543 sec)\n",
      "(73%): 18600000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.30553197860717773 sec)\n",
      "(73%): 18700000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.30702686309814453 sec)\n",
      "(74%): 18800000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.30504631996154785 sec)\n",
      "(74%): 18900000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.31049323081970215 sec)\n",
      "(74%): 19000000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.30501246452331543 sec)\n",
      "(75%): 19100000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.30457353591918945 sec)\n",
      "(75%): 19200000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3050103187561035 sec)\n",
      "(75%): 19300000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3055696487426758 sec)\n",
      "(76%): 19400000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.305039644241333 sec)\n",
      "(76%): 19500000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.305034875869751 sec)\n",
      "(77%): 19600000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3050401210784912 sec)\n",
      "(77%): 19700000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.30504536628723145 sec)\n",
      "(77%): 19800000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.305042028427124 sec)\n",
      "(78%): 19900000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.30553483963012695 sec)\n",
      "(78%): 20000000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3065338134765625 sec)\n",
      "(79%): 20100000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.30553674697875977 sec)\n",
      "(79%): 20200000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3050360679626465 sec)\n",
      "(79%): 20300000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3025658130645752 sec)\n",
      "(80%): 20400000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.30354881286621094 sec)\n",
      "(80%): 20500000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3105013370513916 sec)\n",
      "(81%): 20600000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3040494918823242 sec)\n",
      "(81%): 20700000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3700127601623535 sec)\n",
      "(81%): 20800000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.30354905128479004 sec)\n",
      "(82%): 20900000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.31297969818115234 sec)\n",
      "(82%): 21000000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3045351505279541 sec)\n",
      "(83%): 21100000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.305511474609375 sec)\n",
      "(83%): 21200000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.30804920196533203 sec)\n",
      "(83%): 21300000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.30354738235473633 sec)\n",
      "(84%): 21400000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3045167922973633 sec)\n",
      "(84%): 21500000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.30556297302246094 sec)\n",
      "(84%): 21600000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3080172538757324 sec)\n",
      "(85%): 21700000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.30553507804870605 sec)\n",
      "(85%): 21800000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3040478229522705 sec)\n",
      "(86%): 21900000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3060033321380615 sec)\n",
      "(86%): 22000000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3234260082244873 sec)\n",
      "(86%): 22100000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.30355191230773926 sec)\n",
      "(87%): 22200000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3070249557495117 sec)\n",
      "(87%): 22300000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.30748653411865234 sec)\n",
      "(88%): 22400000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.31151604652404785 sec)\n",
      "(88%): 22500000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3065304756164551 sec)\n",
      "(88%): 22600000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.30451321601867676 sec)\n",
      "(89%): 22700000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3070254325866699 sec)\n",
      "(89%): 22800000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.30355119705200195 sec)\n",
      "(90%): 22900000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3070523738861084 sec)\n",
      "(90%): 23000000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3040480613708496 sec)\n",
      "(90%): 23100000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.31545591354370117 sec)\n",
      "(91%): 23200000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.30501222610473633 sec)\n",
      "(91%): 23300000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.38688015937805176 sec)\n",
      "(92%): 23400000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.30507731437683105 sec)\n",
      "(92%): 23500000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3189222812652588 sec)\n",
      "(92%): 23600000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.31297779083251953 sec)\n",
      "(93%): 23700000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.30901169776916504 sec)\n",
      "(93%): 23800000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3149600028991699 sec)\n",
      "(93%): 23900000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.319887638092041 sec)\n",
      "(94%): 24000000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3060603141784668 sec)\n",
      "(94%): 24100000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.30603814125061035 sec)\n",
      "(95%): 24200000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.30404186248779297 sec)\n",
      "(95%): 24300000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3030550479888916 sec)\n",
      "(95%): 24400000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.301072359085083 sec)\n",
      "(96%): 24500000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3020920753479004 sec)\n",
      "(96%): 24600000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3025634288787842 sec)\n",
      "(97%): 24700000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.30255866050720215 sec)\n",
      "(97%): 24800000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.30306196212768555 sec)\n",
      "(97%): 24900000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3025553226470947 sec)\n",
      "(98%): 25000000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3050386905670166 sec)\n",
      "(98%): 25100000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.30603599548339844 sec)\n",
      "(99%): 25200000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3055381774902344 sec)\n",
      "(99%): 25300000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.3075141906738281 sec)\n",
      "(99%): 25400000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.30603718757629395 sec)\n",
      "(100%): 25500000 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (0.30553531646728516 sec)\n",
      "Done loading ../data/parsed-export/16-dec/parsed_retweets.json\n",
      "25566698 lines in ../data/parsed-export/16-dec/parsed_retweets.json processed (78.66323208808899 sec)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25566698 entries, 0 to 25566697\n",
      "Data columns (total 4 columns):\n",
      " #   Column              Dtype \n",
      "---  ------              ----- \n",
      " 0   user                object\n",
      " 1   timestamp           object\n",
      " 2   retweeted           object\n",
      " 3   retweetedFrom_user  object\n",
      "dtypes: object(4)\n",
      "memory usage: 780.2+ MB\n"
     ]
    }
   ],
   "source": [
    "retweet_df = create_retweet_df(data_dir=DATA_DIR)\n",
    "retweet_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'2020-10-23T16:59:58Z'"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "retweet_df.timestamp.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading 7609005 json lines\n",
      "(1%): 100000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (1.7761523723602295 sec)\n",
      "(3%): 200000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (1.7935664653778076 sec)\n",
      "(4%): 300000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (2.0836968421936035 sec)\n",
      "(5%): 400000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (1.888756513595581 sec)\n",
      "(7%): 500000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (2.039039134979248 sec)\n",
      "(8%): 600000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (2.2235922813415527 sec)\n",
      "(9%): 700000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (1.3535923957824707 sec)\n",
      "(11%): 800000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (2.459662914276123 sec)\n",
      "(12%): 900000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (1.3501124382019043 sec)\n",
      "(13%): 1000000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (2.7344346046447754 sec)\n",
      "(14%): 1100000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (1.369938611984253 sec)\n",
      "(16%): 1200000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (3.0747344493865967 sec)\n",
      "(17%): 1300000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (1.2871203422546387 sec)\n",
      "(18%): 1400000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (1.2930786609649658 sec)\n",
      "(20%): 1500000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (1.3490848541259766 sec)\n",
      "(21%): 1600000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (3.512702465057373 sec)\n",
      "(22%): 1700000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (1.3426721096038818 sec)\n",
      "(24%): 1800000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (1.3426728248596191 sec)\n",
      "(25%): 1900000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (1.3699462413787842 sec)\n",
      "(26%): 2000000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (4.046375274658203 sec)\n",
      "(28%): 2100000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (1.3580482006072998 sec)\n",
      "(29%): 2200000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (1.3575234413146973 sec)\n",
      "(30%): 2300000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (1.415618658065796 sec)\n",
      "(32%): 2400000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (4.841948747634888 sec)\n",
      "(33%): 2500000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (1.3634750843048096 sec)\n",
      "(34%): 2600000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (1.3431689739227295 sec)\n",
      "(35%): 2700000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (1.3699827194213867 sec)\n",
      "(37%): 2800000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (1.3580193519592285 sec)\n",
      "(38%): 2900000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (1.3679978847503662 sec)\n",
      "(39%): 3000000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (1.334233283996582 sec)\n",
      "(41%): 3100000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (5.70747971534729 sec)\n",
      "(42%): 3200000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (1.3193540573120117 sec)\n",
      "(43%): 3300000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (1.33821439743042 sec)\n",
      "(45%): 3400000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (1.3342416286468506 sec)\n",
      "(46%): 3500000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (1.364001989364624 sec)\n",
      "(47%): 3600000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (1.3798694610595703 sec)\n",
      "(49%): 3700000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (1.3620164394378662 sec)\n",
      "(50%): 3800000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (6.9107701778411865 sec)\n",
      "(51%): 3900000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (1.4200193881988525 sec)\n",
      "(53%): 4000000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (1.375439167022705 sec)\n",
      "(54%): 4100000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (1.3545761108398438 sec)\n",
      "(55%): 4200000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (1.3361942768096924 sec)\n",
      "(57%): 4300000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (1.381887435913086 sec)\n",
      "(58%): 4400000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (1.3401947021484375 sec)\n",
      "(59%): 4500000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (1.369452714920044 sec)\n",
      "(60%): 4600000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (1.3635363578796387 sec)\n",
      "(62%): 4700000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (1.3704593181610107 sec)\n",
      "(63%): 4800000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (8.32586407661438 sec)\n",
      "(64%): 4900000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (1.4011712074279785 sec)\n",
      "(66%): 5000000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (1.395277976989746 sec)\n",
      "(67%): 5100000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (1.4017021656036377 sec)\n",
      "(68%): 5200000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (1.327291488647461 sec)\n",
      "(70%): 5300000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (1.352637529373169 sec)\n",
      "(71%): 5400000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (1.3887946605682373 sec)\n",
      "(72%): 5500000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (1.3857462406158447 sec)\n",
      "(74%): 5600000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (1.4122076034545898 sec)\n",
      "(75%): 5700000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (1.729783535003662 sec)\n",
      "(76%): 5800000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (1.44907808303833 sec)\n",
      "(78%): 5900000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (1.3322560787200928 sec)\n",
      "(79%): 6000000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (10.023519515991211 sec)\n",
      "(80%): 6100000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (1.530531406402588 sec)\n",
      "(81%): 6200000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (1.4549891948699951 sec)\n",
      "(83%): 6300000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (1.370267629623413 sec)\n",
      "(84%): 6400000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (1.3830456733703613 sec)\n",
      "(85%): 6500000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (1.7317357063293457 sec)\n",
      "(87%): 6600000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (1.386052131652832 sec)\n",
      "(88%): 6700000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (1.4676930904388428 sec)\n",
      "(89%): 6800000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (1.3352992534637451 sec)\n",
      "(91%): 6900000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (1.4536614418029785 sec)\n",
      "(92%): 7000000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (3.248304605484009 sec)\n",
      "(93%): 7100000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (1.9380435943603516 sec)\n",
      "(95%): 7200000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (1.4810872077941895 sec)\n",
      "(96%): 7300000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (1.4165916442871094 sec)\n",
      "(97%): 7400000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (1.488292932510376 sec)\n",
      "(99%): 7500000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (17.297604084014893 sec)\n",
      "(100%): 7600000 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (1.4508006572723389 sec)\n",
      "Done loading ../data/parsed-export/16-dec/parsed_tweets.json\n",
      "7609005 lines in ../data/parsed-export/16-dec/parsed_tweets.json processed (165.3183991909027 sec)\n"
     ]
    }
   ],
   "source": [
    "old_tweet_df, recent_tweet_df = create_tweet_df(\n",
    "    # retweet_df.timestamp.min()\n",
    "    '2020-10-23T16:59:58Z', \n",
    "    CRAWLED_TERMS, \n",
    "    data_dir=DATA_DIR\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading 1388621 json lines\n",
      "(7%): 100000 lines in ../data/parsed-export/16-dec/parsed_users.json processed (0.7529048919677734 sec)\n",
      "(14%): 200000 lines in ../data/parsed-export/16-dec/parsed_users.json processed (0.7336137294769287 sec)\n",
      "(22%): 300000 lines in ../data/parsed-export/16-dec/parsed_users.json processed (0.7122550010681152 sec)\n",
      "(29%): 400000 lines in ../data/parsed-export/16-dec/parsed_users.json processed (0.7395315170288086 sec)\n",
      "(36%): 500000 lines in ../data/parsed-export/16-dec/parsed_users.json processed (0.7172107696533203 sec)\n",
      "(43%): 600000 lines in ../data/parsed-export/16-dec/parsed_users.json processed (0.6745357513427734 sec)\n",
      "(50%): 700000 lines in ../data/parsed-export/16-dec/parsed_users.json processed (0.7058088779449463 sec)\n",
      "(58%): 800000 lines in ../data/parsed-export/16-dec/parsed_users.json processed (0.7117612361907959 sec)\n",
      "(65%): 900000 lines in ../data/parsed-export/16-dec/parsed_users.json processed (0.6959114074707031 sec)\n",
      "(72%): 1000000 lines in ../data/parsed-export/16-dec/parsed_users.json processed (0.7127559185028076 sec)\n",
      "(79%): 1100000 lines in ../data/parsed-export/16-dec/parsed_users.json processed (0.7038266658782959 sec)\n",
      "(86%): 1200000 lines in ../data/parsed-export/16-dec/parsed_users.json processed (0.6904277801513672 sec)\n",
      "(94%): 1300000 lines in ../data/parsed-export/16-dec/parsed_users.json processed (0.7018413543701172 sec)\n",
      "Done loading ../data/parsed-export/16-dec/parsed_users.json\n",
      "1388621 lines in ../data/parsed-export/16-dec/parsed_users.json processed (9.867899179458618 sec)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1388621 entries, 1001056184256876546 to 1280698446047965185\n",
      "Data columns (total 12 columns):\n",
      " #   Column           Non-Null Count    Dtype \n",
      "---  ------           --------------    ----- \n",
      " 0   followed_cnts    1388621 non-null  int32 \n",
      " 1   friends_count    1388621 non-null  int32 \n",
      " 2   location         809824 non-null   object\n",
      " 3   protected        1388621 non-null  bool  \n",
      " 4   friends          0 non-null        object\n",
      " 5   description      1049923 non-null  object\n",
      " 6   created_at       1388621 non-null  object\n",
      " 7   url              243012 non-null   object\n",
      " 8   verified         1388621 non-null  bool  \n",
      " 9   followers_count  1388621 non-null  int32 \n",
      " 10  handle           1388621 non-null  object\n",
      " 11  name             1388621 non-null  object\n",
      "dtypes: bool(2), int32(3), object(7)\n",
      "memory usage: 103.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df_users = create_user_df(data_dir=DATA_DIR)\n",
    "df_users.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading 479696 json lines\n",
      "(21%): 100000 lines in ../data/05-jan//parsed_media.json processed (1.0534050464630127 sec)\n",
      "(42%): 200000 lines in ../data/05-jan//parsed_media.json processed (1.0033552646636963 sec)\n",
      "(63%): 300000 lines in ../data/05-jan//parsed_media.json processed (1.264967918395996 sec)\n",
      "(83%): 400000 lines in ../data/05-jan//parsed_media.json processed (1.1196410655975342 sec)\n",
      "Done loading ../data/05-jan//parsed_media.json\n",
      "479696 lines in ../data/05-jan//parsed_media.json processed (5.232635974884033 sec)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 201259 entries, 5327346445844480 to 5114016670154752\n",
      "Data columns (total 53 columns):\n",
      " #   Column                      Non-Null Count   Dtype           \n",
      "---  ------                      --------------   -----           \n",
      " 0   w_hash                      201259 non-null  object          \n",
      " 1   tweet_id                    201259 non-null  object          \n",
      " 2   p_hash                      201259 non-null  object          \n",
      " 3   media_id                    201259 non-null  object          \n",
      " 4   a_hash                      201259 non-null  object          \n",
      " 5   type                        201259 non-null  object          \n",
      " 6   media_url                   201259 non-null  object          \n",
      " 7   urls                        201259 non-null  object          \n",
      " 8   hasMedia                    201259 non-null  bool            \n",
      " 9   hashtags                    201259 non-null  object          \n",
      " 10  retweet_count               201259 non-null  int32           \n",
      " 11  quote_count                 201259 non-null  int32           \n",
      " 12  user                        201259 non-null  object          \n",
      " 13  text                        201259 non-null  object          \n",
      " 14  quote_tweet                 94890 non-null   object          \n",
      " 15  timestamp                   201259 non-null  object          \n",
      " 16  tokens                      201259 non-null  object          \n",
      " 17  election fraud              201259 non-null  Sparse[int64, 0]\n",
      " 18  voter fraud                 201259 non-null  Sparse[int64, 0]\n",
      " 19  #voterfraud                 201259 non-null  Sparse[int64, 0]\n",
      " 20  #stopthesteal               201259 non-null  Sparse[int64, 0]\n",
      " 21  #ballotharvesting           201259 non-null  Sparse[int64, 0]\n",
      " 22  ballot fraud                201259 non-null  Sparse[int64, 0]\n",
      " 23  #electionfraud              201259 non-null  Sparse[int64, 0]\n",
      " 24  #electioninterference       201259 non-null  Sparse[int64, 0]\n",
      " 25  ballot harvesting           201259 non-null  Sparse[int64, 0]\n",
      " 26  election interference       201259 non-null  Sparse[int64, 0]\n",
      " 27  #electiontampering          201259 non-null  Sparse[int64, 0]\n",
      " 28  #cheatingdemocrats          201259 non-null  Sparse[int64, 0]\n",
      " 29  election tampering          201259 non-null  Sparse[int64, 0]\n",
      " 30  democrats cheat             201259 non-null  Sparse[int64, 0]\n",
      " 31  #voterfraudisreal           201259 non-null  Sparse[int64, 0]\n",
      " 32  cheating democrats          201259 non-null  Sparse[int64, 0]\n",
      " 33  #gopvoterfraud              201259 non-null  Sparse[int64, 0]\n",
      " 34  destroyed ballots           201259 non-null  Sparse[int64, 0]\n",
      " 35  stolen ballots              201259 non-null  Sparse[int64, 0]\n",
      " 36  #ballotfraud                201259 non-null  Sparse[int64, 0]\n",
      " 37  discarded ballots           201259 non-null  Sparse[int64, 0]\n",
      " 38  hacked voting machine       201259 non-null  Sparse[int64, 0]\n",
      " 39  pre-filled ballot           201259 non-null  Sparse[int64, 0]\n",
      " 40  harvest ballot              201259 non-null  Sparse[int64, 0]\n",
      " 41  #stopvoterfraud             201259 non-null  Sparse[int64, 0]\n",
      " 42  #democratvoterfraud         201259 non-null  Sparse[int64, 0]\n",
      " 43  #ballotvoterfraud           201259 non-null  Sparse[int64, 0]\n",
      " 44  #nomailinvoting             201259 non-null  Sparse[int64, 0]\n",
      " 45  #ilhanomarballotharvesting  201259 non-null  Sparse[int64, 0]\n",
      " 46  vote by mail fraud          201259 non-null  Sparse[int64, 0]\n",
      " 47  #mailinvoterfraud           201259 non-null  Sparse[int64, 0]\n",
      " 48  #votebymailfraud            201259 non-null  Sparse[int64, 0]\n",
      " 49  #ilhanomarvoterfraud        201259 non-null  Sparse[int64, 0]\n",
      " 50  #stopgopvoterfraud          201259 non-null  Sparse[int64, 0]\n",
      " 51  #discardedballots           201259 non-null  Sparse[int64, 0]\n",
      " 52  #hackedvotingmachines       201259 non-null  Sparse[int64, 0]\n",
      "dtypes: Sparse[int64, 0](36), bool(1), int32(2), object(14)\n",
      "memory usage: 26.0+ MB\n"
     ]
    }
   ],
   "source": [
    "from data_tools import lookup_parsed_data, load_parsed_data\n",
    "\n",
    "# load from 05-jan dump because it contains hashes\n",
    "df_media_with_tweets = create_media_df(recent_tweet_df, \"../data/05-jan/\")\n",
    "df_media_with_tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 36 entries, 35 to 15\nData columns (total 2 columns):\n #   Column       Non-Null Count  Dtype \n---  ------       --------------  ----- \n 0   term         36 non-null     object\n 1   tweet count  36 non-null     int64 \ndtypes: int64(1), object(1)\nmemory usage: 864.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "def create_crawled_terms_df(crawled_terms, tweet_df):\n",
    "    crawled_terms_stats = []\n",
    "\n",
    "    for term in crawled_terms:\n",
    "        if term in tweet_df.columns:\n",
    "            stats = {}\n",
    "            stats[\"term\"] = term\n",
    "            stats[\"tweet count\"] = tweet_df[term].value_counts().values[1]\n",
    "            crawled_terms_stats.append(stats)\n",
    "\n",
    "    crawled_terms_df = pd.DataFrame(crawled_terms_stats).sort_values(\n",
    "        by=[\"tweet count\"], ascending=False\n",
    "    )\n",
    "\n",
    "    return crawled_terms_df\n",
    "\n",
    "crawled_terms_df = create_crawled_terms_df(CRAWLED_TERMS, recent_tweet_df)\n",
    "crawled_terms_df.info()"
   ]
  },
  {
   "source": [
    "## Basic stats & Coverage"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "\n",
    "coverage_stats = {}\n",
    "\n",
    "coverage_stats[\"old_tweet_count\"] = len(old_tweet_df.index)\n",
    "coverage_stats[\"recent_tweet_count\"] = len(recent_tweet_df.index)\n",
    "coverage_stats[\"total_tweet_count\"] = coverage_stats[\"recent_tweet_count\"] + coverage_stats[\"old_tweet_count\"]\n",
    "coverage_stats[\"retweet_count\"] = len(retweet_df.index)\n",
    "coverage_stats[\"user_count\"] = len(df_users.index)\n",
    "\n",
    "coverage_stats[\"earliest_tweet\"] = recent_tweet_df.timestamp.min()\n",
    "coverage_stats[\"latest_tweet\"] = recent_tweet_df.timestamp.max()\n",
    "coverage_stats[\"earliest_retweet\"] = retweet_df.timestamp.min()\n",
    "coverage_stats[\"latest_retweet\"] = retweet_df.timestamp.max()\n",
    "\n",
    "coverage_stats"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'old_tweet_count': 5902,\n",
       " 'recent_tweet_count': 7603103,\n",
       " 'total_tweet_count': 7609005,\n",
       " 'retweet_count': 25566698,\n",
       " 'user_count': 1388621,\n",
       " 'earliest_tweet': '2008-11-05T02:44:00Z',\n",
       " 'latest_tweet': '2020-12-16T13:08:49Z',\n",
       " 'earliest_retweet': '2020-10-23T16:59:58Z',\n",
       " 'latest_retweet': '2020-12-16T13:42:14Z'}"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ]
  },
  {
   "source": [
    "## Terms grouped by hour"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                           tweet count  retweet count  voter fraud  \\\n",
       "date                                                                 \n",
       "2020-10-23 17:00:00+00:00          306          681.0          179   \n",
       "2020-10-23 18:00:00+00:00          419         1272.0          238   \n",
       "2020-10-23 19:00:00+00:00          409          561.0          250   \n",
       "2020-10-23 20:00:00+00:00          645          932.0          372   \n",
       "2020-10-23 21:00:00+00:00          539          847.0          322   \n",
       "\n",
       "                           election fraud  #stopthesteal  #voterfraud  \\\n",
       "date                                                                    \n",
       "2020-10-23 17:00:00+00:00             4.0            0.0         24.0   \n",
       "2020-10-23 18:00:00+00:00             9.0            0.0         22.0   \n",
       "2020-10-23 19:00:00+00:00             8.0            1.0         50.0   \n",
       "2020-10-23 20:00:00+00:00            18.0            0.0         77.0   \n",
       "2020-10-23 21:00:00+00:00            11.0            0.0         57.0   \n",
       "\n",
       "                           #electionfraud  election interference  \\\n",
       "date                                                               \n",
       "2020-10-23 17:00:00+00:00             0.0                    0.0   \n",
       "2020-10-23 18:00:00+00:00             1.0                    0.0   \n",
       "2020-10-23 19:00:00+00:00             0.0                    2.0   \n",
       "2020-10-23 20:00:00+00:00             2.0                    2.0   \n",
       "2020-10-23 21:00:00+00:00             1.0                    0.0   \n",
       "\n",
       "                           ballot harvesting  ballot fraud  ...  \\\n",
       "date                                                        ...   \n",
       "2020-10-23 17:00:00+00:00                0.0           0.0  ...   \n",
       "2020-10-23 18:00:00+00:00                3.0           2.0  ...   \n",
       "2020-10-23 19:00:00+00:00                4.0           1.0  ...   \n",
       "2020-10-23 20:00:00+00:00                6.0           6.0  ...   \n",
       "2020-10-23 21:00:00+00:00                4.0           3.0  ...   \n",
       "\n",
       "                           hacked voting machine  pre-filled ballot  \\\n",
       "date                                                                  \n",
       "2020-10-23 17:00:00+00:00                    0.0                0.0   \n",
       "2020-10-23 18:00:00+00:00                    0.0                0.0   \n",
       "2020-10-23 19:00:00+00:00                    0.0                0.0   \n",
       "2020-10-23 20:00:00+00:00                    0.0                0.0   \n",
       "2020-10-23 21:00:00+00:00                    0.0                0.0   \n",
       "\n",
       "                           #ilhanomarballotharvesting  #ballotvoterfraud  \\\n",
       "date                                                                       \n",
       "2020-10-23 17:00:00+00:00                         0.0                0.0   \n",
       "2020-10-23 18:00:00+00:00                         0.0                0.0   \n",
       "2020-10-23 19:00:00+00:00                         0.0                0.0   \n",
       "2020-10-23 20:00:00+00:00                         0.0                0.0   \n",
       "2020-10-23 21:00:00+00:00                         0.0                0.0   \n",
       "\n",
       "                           #votebymailfraud  #nomailinvoting  \\\n",
       "date                                                           \n",
       "2020-10-23 17:00:00+00:00               0.0              0.0   \n",
       "2020-10-23 18:00:00+00:00               0.0              0.0   \n",
       "2020-10-23 19:00:00+00:00               0.0              0.0   \n",
       "2020-10-23 20:00:00+00:00               0.0              0.0   \n",
       "2020-10-23 21:00:00+00:00               0.0              0.0   \n",
       "\n",
       "                           #ilhanomarvoterfraud  #hackedvotingmachines  \\\n",
       "date                                                                     \n",
       "2020-10-23 17:00:00+00:00                   0.0                    0.0   \n",
       "2020-10-23 18:00:00+00:00                   0.0                    0.0   \n",
       "2020-10-23 19:00:00+00:00                   0.0                    0.0   \n",
       "2020-10-23 20:00:00+00:00                   0.0                    0.0   \n",
       "2020-10-23 21:00:00+00:00                   0.0                    0.0   \n",
       "\n",
       "                           #discardedballots  #stopgopvoterfraud  \n",
       "date                                                              \n",
       "2020-10-23 17:00:00+00:00                0.0                 0.0  \n",
       "2020-10-23 18:00:00+00:00                0.0                 0.0  \n",
       "2020-10-23 19:00:00+00:00                0.0                 0.0  \n",
       "2020-10-23 20:00:00+00:00                0.0                 0.0  \n",
       "2020-10-23 21:00:00+00:00                0.0                 0.0  \n",
       "\n",
       "[5 rows x 38 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet count</th>\n      <th>retweet count</th>\n      <th>voter fraud</th>\n      <th>election fraud</th>\n      <th>#stopthesteal</th>\n      <th>#voterfraud</th>\n      <th>#electionfraud</th>\n      <th>election interference</th>\n      <th>ballot harvesting</th>\n      <th>ballot fraud</th>\n      <th>...</th>\n      <th>hacked voting machine</th>\n      <th>pre-filled ballot</th>\n      <th>#ilhanomarballotharvesting</th>\n      <th>#ballotvoterfraud</th>\n      <th>#votebymailfraud</th>\n      <th>#nomailinvoting</th>\n      <th>#ilhanomarvoterfraud</th>\n      <th>#hackedvotingmachines</th>\n      <th>#discardedballots</th>\n      <th>#stopgopvoterfraud</th>\n    </tr>\n    <tr>\n      <th>date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2020-10-23 17:00:00+00:00</th>\n      <td>306</td>\n      <td>681.0</td>\n      <td>179</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>24.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2020-10-23 18:00:00+00:00</th>\n      <td>419</td>\n      <td>1272.0</td>\n      <td>238</td>\n      <td>9.0</td>\n      <td>0.0</td>\n      <td>22.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2020-10-23 19:00:00+00:00</th>\n      <td>409</td>\n      <td>561.0</td>\n      <td>250</td>\n      <td>8.0</td>\n      <td>1.0</td>\n      <td>50.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2020-10-23 20:00:00+00:00</th>\n      <td>645</td>\n      <td>932.0</td>\n      <td>372</td>\n      <td>18.0</td>\n      <td>0.0</td>\n      <td>77.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2020-10-23 21:00:00+00:00</th>\n      <td>539</td>\n      <td>847.0</td>\n      <td>322</td>\n      <td>11.0</td>\n      <td>0.0</td>\n      <td>57.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 38 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "df_aggregated_by_hour = aggregate_counts_by_hour(recent_tweet_df, retweet_df, crawled_terms_df[\"term\"].values)\n",
    "df_aggregated_by_hour.head()"
   ]
  },
  {
   "source": [
    "## Most common hashtags"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "               all tweets  voter fraud  election fraud  #stopthesteal  \\\n",
       "hashtag                                                                 \n",
       "#1                      0          741             530              0   \n",
       "#12news                 0            0               0              0   \n",
       "#1a                     0            0               0              0   \n",
       "#2                      0            0               0              0   \n",
       "#2020election        9507          934             701           2282   \n",
       "\n",
       "               #voterfraud  #electionfraud  election interference  \\\n",
       "hashtag                                                             \n",
       "#1                       0               0                     47   \n",
       "#12news                  0               0                      0   \n",
       "#1a                      0               0                      0   \n",
       "#2                       0               0                      0   \n",
       "#2020election         2680            2608                     62   \n",
       "\n",
       "               ballot harvesting  ballot fraud  #electioninterference  ...  \\\n",
       "hashtag                                                                ...   \n",
       "#1                            21            18                      0  ...   \n",
       "#12news                        0             0                      0  ...   \n",
       "#1a                            0             0                      0  ...   \n",
       "#2                            12             0                      0  ...   \n",
       "#2020election                 14            19                    340  ...   \n",
       "\n",
       "               hacked voting machine  pre-filled ballot  \\\n",
       "hashtag                                                   \n",
       "#1                                 0                  0   \n",
       "#12news                            0                  0   \n",
       "#1a                                0                  0   \n",
       "#2                                 0                  0   \n",
       "#2020election                      0                  0   \n",
       "\n",
       "               #ilhanomarballotharvesting  #ballotvoterfraud  \\\n",
       "hashtag                                                        \n",
       "#1                                      0                  0   \n",
       "#12news                                 0                  0   \n",
       "#1a                                     0                  0   \n",
       "#2                                      0                  0   \n",
       "#2020election                           0                  2   \n",
       "\n",
       "               #votebymailfraud  #nomailinvoting  #ilhanomarvoterfraud  \\\n",
       "hashtag                                                                  \n",
       "#1                            0                0                     0   \n",
       "#12news                       0                0                     0   \n",
       "#1a                           0                0                     0   \n",
       "#2                            0                0                     0   \n",
       "#2020election                 0                0                     0   \n",
       "\n",
       "               #hackedvotingmachines  #discardedballots  #stopgopvoterfraud  \n",
       "hashtag                                                                      \n",
       "#1                                 0                  0                   0  \n",
       "#12news                            0                  0                   0  \n",
       "#1a                                0                  0                   0  \n",
       "#2                                 0                  0                   0  \n",
       "#2020election                      0                  0                   0  \n",
       "\n",
       "[5 rows x 37 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>all tweets</th>\n      <th>voter fraud</th>\n      <th>election fraud</th>\n      <th>#stopthesteal</th>\n      <th>#voterfraud</th>\n      <th>#electionfraud</th>\n      <th>election interference</th>\n      <th>ballot harvesting</th>\n      <th>ballot fraud</th>\n      <th>#electioninterference</th>\n      <th>...</th>\n      <th>hacked voting machine</th>\n      <th>pre-filled ballot</th>\n      <th>#ilhanomarballotharvesting</th>\n      <th>#ballotvoterfraud</th>\n      <th>#votebymailfraud</th>\n      <th>#nomailinvoting</th>\n      <th>#ilhanomarvoterfraud</th>\n      <th>#hackedvotingmachines</th>\n      <th>#discardedballots</th>\n      <th>#stopgopvoterfraud</th>\n    </tr>\n    <tr>\n      <th>hashtag</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>#1</th>\n      <td>0</td>\n      <td>741</td>\n      <td>530</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>47</td>\n      <td>21</td>\n      <td>18</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>#12news</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>#1a</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>#2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>12</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>#2020election</th>\n      <td>9507</td>\n      <td>934</td>\n      <td>701</td>\n      <td>2282</td>\n      <td>2680</td>\n      <td>2608</td>\n      <td>62</td>\n      <td>14</td>\n      <td>19</td>\n      <td>340</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 37 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "df_most_common_hashtags = aggregate_most_common_hashtags(recent_tweet_df, crawled_terms_df[\"term\"].values)\n",
    "df_most_common_hashtags.head()"
   ]
  },
  {
   "source": [
    "## Most common tokens"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       all tweets  voter fraud  election fraud  #stopthesteal  #voterfraud  \\\n",
       "token                                                                        \n",
       "1               0            0               0              0            0   \n",
       "10              0            0               0              0            0   \n",
       "100             0            0               0              0            0   \n",
       "10000           0            0               0              0            0   \n",
       "1000s           0            0               0              0            0   \n",
       "\n",
       "       #electionfraud  election interference  ballot harvesting  ballot fraud  \\\n",
       "token                                                                           \n",
       "1                   0                      0                  0             0   \n",
       "10                  0                      0                  0             0   \n",
       "100                 0                      0                  0             0   \n",
       "10000               0                      0                  0             0   \n",
       "1000s               0                      0                  0             0   \n",
       "\n",
       "       #electioninterference  ...  hacked voting machine  pre-filled ballot  \\\n",
       "token                         ...                                             \n",
       "1                          0  ...                     17                  8   \n",
       "10                       206  ...                      0                  0   \n",
       "100                        0  ...                      0                  0   \n",
       "10000                      0  ...                      0                  0   \n",
       "1000s                      0  ...                      0                  0   \n",
       "\n",
       "       #ilhanomarballotharvesting  #ballotvoterfraud  #votebymailfraud  \\\n",
       "token                                                                    \n",
       "1                               0                  0                 1   \n",
       "10                              0                  0                 0   \n",
       "100                             0                  0                 0   \n",
       "10000                           0                  1                 0   \n",
       "1000s                           0                  0                 1   \n",
       "\n",
       "       #nomailinvoting  #ilhanomarvoterfraud  #hackedvotingmachines  \\\n",
       "token                                                                 \n",
       "1                    0                     0                      0   \n",
       "10                   0                     0                      0   \n",
       "100                  0                     0                      0   \n",
       "10000                0                     0                      0   \n",
       "1000s                0                     0                      0   \n",
       "\n",
       "       #discardedballots  #stopgopvoterfraud  \n",
       "token                                         \n",
       "1                      0                   0  \n",
       "10                     0                   0  \n",
       "100                    0                   0  \n",
       "10000                  0                   0  \n",
       "1000s                  0                   0  \n",
       "\n",
       "[5 rows x 37 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>all tweets</th>\n      <th>voter fraud</th>\n      <th>election fraud</th>\n      <th>#stopthesteal</th>\n      <th>#voterfraud</th>\n      <th>#electionfraud</th>\n      <th>election interference</th>\n      <th>ballot harvesting</th>\n      <th>ballot fraud</th>\n      <th>#electioninterference</th>\n      <th>...</th>\n      <th>hacked voting machine</th>\n      <th>pre-filled ballot</th>\n      <th>#ilhanomarballotharvesting</th>\n      <th>#ballotvoterfraud</th>\n      <th>#votebymailfraud</th>\n      <th>#nomailinvoting</th>\n      <th>#ilhanomarvoterfraud</th>\n      <th>#hackedvotingmachines</th>\n      <th>#discardedballots</th>\n      <th>#stopgopvoterfraud</th>\n    </tr>\n    <tr>\n      <th>token</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>17</td>\n      <td>8</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>206</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>100</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10000</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1000s</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 37 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "STOP_WORDS = STOP_WORDS.union({\"pron\", \"\", \" \", \"”\", \"“\", \"🇺\"})\n",
    "\n",
    "def include_token(token):\n",
    "    return token not in STOP_WORDS and not token.startswith(\"hashtag\")\n",
    "\n",
    "def create_most_common_tokens_df(df_tweets, count_label, k=100):\n",
    "    counted_tokens = Counter(\n",
    "        [\n",
    "            token\n",
    "            for tokens in df_tweets[\"tokens\"]\n",
    "            for token in tokens\n",
    "            if include_token(token)\n",
    "        ]\n",
    "    )\n",
    "    return pd.DataFrame(\n",
    "        counted_tokens.most_common(k), columns=[\"token\", count_label]\n",
    "    ).set_index(\"token\")\n",
    "\n",
    "def aggregate_most_common_tokens(df_tweets, crawled_terms, k=100):\n",
    "    df_most_common_tokens = create_most_common_tokens_df(df_tweets, count_label=\"all tweets\", k=k)\n",
    "    for term in crawled_terms:\n",
    "        filtered_by_crawled_term = df_tweets[\n",
    "            df_tweets[term] == 1\n",
    "        ]\n",
    "        df_most_common_tokens = df_most_common_tokens.join(\n",
    "            create_most_common_tokens_df(filtered_by_crawled_term, count_label=term, k=k),\n",
    "            how='outer'\n",
    "        )\n",
    "    return df_most_common_tokens.fillna(0).astype(int)\n",
    "\n",
    "\n",
    "df_most_common_tokens = aggregate_most_common_tokens(recent_tweet_df, crawled_terms_df[\"term\"].values)\n",
    "df_most_common_tokens.head()"
   ]
  },
  {
   "source": [
    "## Co-occurrence"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crawled_term_threshold = 5000\n",
    "filtered_crawled_terms = crawled_terms_df[\n",
    "    crawled_terms_df[\"tweet count\"] > crawled_term_threshold\n",
    "]\n",
    "terms_in_df = [term for term in filtered_crawled_terms[\"term\"]]\n",
    "crawled_terms_tweet_df = (\n",
    "    recent_tweet_df[terms_in_df].sparse.to_dense().astype(\"int32\")\n",
    ")\n",
    "df_cooccurrence = crawled_terms_tweet_df.T.dot(crawled_terms_tweet_df)"
   ]
  },
  {
   "source": [
    "## Quote Tweets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quote_tweets = recent_tweet_df[recent_tweet_df[\"quote_tweet\"].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add quote tweet count to coverage stats and update earliest_tweet\n",
    "with open(EXPORT_DIR + \"coverage_stats.pickle\", \"rb\") as f:\n",
    "    coverage_stats = pickle.load(f)\n",
    "    coverage_stats[\"quote_tweet_count\"] = df_quote_tweets.shape[0]\n",
    "    coverage_stats[\"earliest_tweet\"] = recent_tweet_df[\"timestamp\"].min()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'old_tweet_count': 5902, 'recent_tweet_count': 7603103, 'total_tweet_count': 7609005, 'retweet_count': 25566698, 'user_count': 1388621, 'earliest_tweet': '2020-10-23T17:00:04Z', 'latest_tweet': '2020-12-16T13:08:49Z', 'earliest_retweet': '2020-10-23T16:59:58Z', 'latest_retweet': '2020-12-16T13:42:14Z', 'quote_tweet_count': 3821579}\n"
     ]
    }
   ],
   "source": [
    "print(coverage_stats)"
   ]
  },
  {
   "source": [
    "## Top tweets by week\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                               datastore_id  quote_count  retweet_count  \\\n",
       "WeekDate     user                                                         \n",
       "2020-10-19 0 259001548  1320117044612943872        10199          34530   \n",
       "           1 341194704  1320107370312323073         9158          22217   \n",
       "           2 25073877   1320168905856397326          941          17118   \n",
       "           3 137752344  1320161049769889792         2846          15897   \n",
       "           4 39349894   1320160474672095232         3736          14948   \n",
       "\n",
       "                       hasMedia  \\\n",
       "WeekDate     user                 \n",
       "2020-10-19 0 259001548    False   \n",
       "           1 341194704    False   \n",
       "           2 25073877     False   \n",
       "           3 137752344    False   \n",
       "           4 39349894     False   \n",
       "\n",
       "                                                                     text  \\\n",
       "WeekDate     user                                                           \n",
       "2020-10-19 0 259001548  🚨🚨 BIDEN ADMITS TO VOTER FRAUD! 🚨🚨\\n\\n@JoeBide...   \n",
       "           1 341194704  👀👀 \\n\\nJoe Biden brags about having “the most ...   \n",
       "           2 25073877   Law Enforcement is watching and involved. So d...   \n",
       "           3 137752344  I hope you’ve been hacked, @GovMikeHuckabee. T...   \n",
       "           4 39349894   😳😳😳\\n\\nBiden: “We have put together the most e...   \n",
       "\n",
       "                                   timestamp           handle  \\\n",
       "WeekDate     user                                               \n",
       "2020-10-19 0 259001548  2020-10-24T21:36:44Z  kayleighmcenany   \n",
       "           1 341194704  2020-10-24T20:58:18Z       SteveGuest   \n",
       "           2 25073877   2020-10-25T01:02:49Z  realDonaldTrump   \n",
       "           3 137752344  2020-10-25T00:31:36Z  EllenLWeintraub   \n",
       "           4 39349894   2020-10-25T00:29:19Z        EricTrump   \n",
       "\n",
       "                                       name  \n",
       "WeekDate     user                            \n",
       "2020-10-19 0 259001548     Kayleigh McEnany  \n",
       "           1 341194704          Steve Guest  \n",
       "           2 25073877       Donald J. Trump  \n",
       "           3 137752344  Ellen L 😷 Weintraub  \n",
       "           4 39349894            Eric Trump  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>datastore_id</th>\n      <th>quote_count</th>\n      <th>retweet_count</th>\n      <th>hasMedia</th>\n      <th>text</th>\n      <th>timestamp</th>\n      <th>handle</th>\n      <th>name</th>\n    </tr>\n    <tr>\n      <th>WeekDate</th>\n      <th></th>\n      <th>user</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">2020-10-19</th>\n      <th>0</th>\n      <th>259001548</th>\n      <td>1320117044612943872</td>\n      <td>10199</td>\n      <td>34530</td>\n      <td>False</td>\n      <td>🚨🚨 BIDEN ADMITS TO VOTER FRAUD! 🚨🚨\\n\\n@JoeBide...</td>\n      <td>2020-10-24T21:36:44Z</td>\n      <td>kayleighmcenany</td>\n      <td>Kayleigh McEnany</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <th>341194704</th>\n      <td>1320107370312323073</td>\n      <td>9158</td>\n      <td>22217</td>\n      <td>False</td>\n      <td>👀👀 \\n\\nJoe Biden brags about having “the most ...</td>\n      <td>2020-10-24T20:58:18Z</td>\n      <td>SteveGuest</td>\n      <td>Steve Guest</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <th>25073877</th>\n      <td>1320168905856397326</td>\n      <td>941</td>\n      <td>17118</td>\n      <td>False</td>\n      <td>Law Enforcement is watching and involved. So d...</td>\n      <td>2020-10-25T01:02:49Z</td>\n      <td>realDonaldTrump</td>\n      <td>Donald J. Trump</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <th>137752344</th>\n      <td>1320161049769889792</td>\n      <td>2846</td>\n      <td>15897</td>\n      <td>False</td>\n      <td>I hope you’ve been hacked, @GovMikeHuckabee. T...</td>\n      <td>2020-10-25T00:31:36Z</td>\n      <td>EllenLWeintraub</td>\n      <td>Ellen L 😷 Weintraub</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <th>39349894</th>\n      <td>1320160474672095232</td>\n      <td>3736</td>\n      <td>14948</td>\n      <td>False</td>\n      <td>😳😳😳\\n\\nBiden: “We have put together the most e...</td>\n      <td>2020-10-25T00:29:19Z</td>\n      <td>EricTrump</td>\n      <td>Eric Trump</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "import datetime as dt\n",
    "tweets = recent_tweet_df\n",
    "tweets['WeekDate'] = pd.to_datetime(tweets.timestamp).dt.to_period('W').apply(lambda r: r.start_time)\n",
    "weeks = tweets['WeekDate'].unique()\n",
    "\n",
    "def extract_weekly_tweets(df_week, N=25):\n",
    "    media_tweets = df_week[df_week[\"hasMedia\"]]\n",
    "    top_retweeted = df_week.nlargest(N, \"retweet_count\")\n",
    "    top_quoted = df_week.nlargest(N, \"quote_count\")\n",
    "    media_top_retweeted = media_tweets.nlargest(N, \"retweet_count\")\n",
    "    media_top_quoted = media_tweets.nlargest(N, \"quote_count\")\n",
    "    return (top_retweeted.merge(top_quoted, how=\"outer\")\n",
    "                        .merge(media_top_retweeted, how=\"outer\")\n",
    "                        .merge(media_top_quoted, how=\"outer\"))\n",
    "\n",
    "columns = [\"datastore_id\", \"quote_count\", \"retweet_count\", \"hasMedia\", \"text\", \"user\", \"timestamp\"]\n",
    "weekly_top_tweets = (tweets\n",
    "    .groupby(\"WeekDate\")[columns]\n",
    "    .apply(lambda df: extract_weekly_tweets(df))\n",
    "#  Merge with user df and sort by week date, retweet count\n",
    "    .merge(df_users[[\"handle\", \"name\"]], how='inner', left_on=\"user\", right_index=True)\n",
    "    .set_index(\"user\", append=True)\n",
    "    .sort_values(by=['WeekDate', 'retweet_count'], ascending=[True, False]))\n",
    "weekly_top_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(554, 8)"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "weekly_top_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "print(len(weeks))"
   ]
  },
  {
   "source": [
    "## Top users by week\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                retweeted_count  quoted_count  \\\n",
       "WeekDate   user                                                 \n",
       "2020-10-19 1316429019198500865               11             3   \n",
       "           1225026641614774273                0             0   \n",
       "           1225835542765395968                0             0   \n",
       "           2937103496                         0             0   \n",
       "           410022823                          0             0   \n",
       "\n",
       "                                all_tweet_count  media_tweet_count  \\\n",
       "WeekDate   user                                                      \n",
       "2020-10-19 1316429019198500865               33                 29   \n",
       "           1225026641614774273               12                 11   \n",
       "           1225835542765395968               10                 10   \n",
       "           2937103496                         9                  8   \n",
       "           410022823                         13                  8   \n",
       "\n",
       "                                quote_tweet_count  protected friends  \\\n",
       "WeekDate   user                                                        \n",
       "2020-10-19 1316429019198500865                  1      False    None   \n",
       "           1225026641614774273                  0      False    None   \n",
       "           1225835542765395968                  0      False    None   \n",
       "           2937103496                           0      False    None   \n",
       "           410022823                           13      False    None   \n",
       "\n",
       "                                          created_at                     name  \\\n",
       "WeekDate   user                                                                 \n",
       "2020-10-19 1316429019198500865  2020-10-14T17:22:27Z          Chalmatian70043   \n",
       "           1225026641614774273  2020-02-05T12:01:42Z        Philip Castilleja   \n",
       "           1225835542765395968  2020-02-07T17:35:59Z            FedupAmerican   \n",
       "           2937103496           2014-12-20T13:06:56Z  Gee.Frank is back y'all   \n",
       "           410022823            2011-11-11T14:49:06Z                    Alan7   \n",
       "\n",
       "                                friends_count  verified  followers_count  \\\n",
       "WeekDate   user                                                            \n",
       "2020-10-19 1316429019198500865             56     False                8   \n",
       "           1225026641614774273             68     False               31   \n",
       "           1225835542765395968           4971     False             4477   \n",
       "           2937103496                    1927     False             2592   \n",
       "           410022823                     4982     False             3349   \n",
       "\n",
       "                                   location  followed_cnts           handle  \\\n",
       "WeekDate   user                                                               \n",
       "2020-10-19 1316429019198500865         None              0  chalmatian70043   \n",
       "           1225026641614774273         None              0  PhilipCastille2   \n",
       "           1225835542765395968         None              0  FedupAm48219051   \n",
       "           2937103496           Alaska, USA              0    Frank_N_Meems   \n",
       "           410022823                   None              0         gohavfun   \n",
       "\n",
       "                                 url  \n",
       "WeekDate   user                       \n",
       "2020-10-19 1316429019198500865  None  \n",
       "           1225026641614774273  None  \n",
       "           1225835542765395968  None  \n",
       "           2937103496           None  \n",
       "           410022823            None  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>retweeted_count</th>\n      <th>quoted_count</th>\n      <th>all_tweet_count</th>\n      <th>media_tweet_count</th>\n      <th>quote_tweet_count</th>\n      <th>protected</th>\n      <th>friends</th>\n      <th>created_at</th>\n      <th>name</th>\n      <th>friends_count</th>\n      <th>verified</th>\n      <th>followers_count</th>\n      <th>location</th>\n      <th>followed_cnts</th>\n      <th>handle</th>\n      <th>url</th>\n    </tr>\n    <tr>\n      <th>WeekDate</th>\n      <th>user</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">2020-10-19</th>\n      <th>1316429019198500865</th>\n      <td>11</td>\n      <td>3</td>\n      <td>33</td>\n      <td>29</td>\n      <td>1</td>\n      <td>False</td>\n      <td>None</td>\n      <td>2020-10-14T17:22:27Z</td>\n      <td>Chalmatian70043</td>\n      <td>56</td>\n      <td>False</td>\n      <td>8</td>\n      <td>None</td>\n      <td>0</td>\n      <td>chalmatian70043</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1225026641614774273</th>\n      <td>0</td>\n      <td>0</td>\n      <td>12</td>\n      <td>11</td>\n      <td>0</td>\n      <td>False</td>\n      <td>None</td>\n      <td>2020-02-05T12:01:42Z</td>\n      <td>Philip Castilleja</td>\n      <td>68</td>\n      <td>False</td>\n      <td>31</td>\n      <td>None</td>\n      <td>0</td>\n      <td>PhilipCastille2</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1225835542765395968</th>\n      <td>0</td>\n      <td>0</td>\n      <td>10</td>\n      <td>10</td>\n      <td>0</td>\n      <td>False</td>\n      <td>None</td>\n      <td>2020-02-07T17:35:59Z</td>\n      <td>FedupAmerican</td>\n      <td>4971</td>\n      <td>False</td>\n      <td>4477</td>\n      <td>None</td>\n      <td>0</td>\n      <td>FedupAm48219051</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>2937103496</th>\n      <td>0</td>\n      <td>0</td>\n      <td>9</td>\n      <td>8</td>\n      <td>0</td>\n      <td>False</td>\n      <td>None</td>\n      <td>2014-12-20T13:06:56Z</td>\n      <td>Gee.Frank is back y'all</td>\n      <td>1927</td>\n      <td>False</td>\n      <td>2592</td>\n      <td>Alaska, USA</td>\n      <td>0</td>\n      <td>Frank_N_Meems</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>410022823</th>\n      <td>0</td>\n      <td>0</td>\n      <td>13</td>\n      <td>8</td>\n      <td>13</td>\n      <td>False</td>\n      <td>None</td>\n      <td>2011-11-11T14:49:06Z</td>\n      <td>Alan7</td>\n      <td>4982</td>\n      <td>False</td>\n      <td>3349</td>\n      <td>None</td>\n      <td>0</td>\n      <td>gohavfun</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "import datetime as dt\n",
    "tweets = recent_tweet_df\n",
    "tweets['WeekDate'] = pd.to_datetime(tweets.timestamp).dt.to_period('W').apply(lambda r: r.start_time)\n",
    "weeks = tweets['WeekDate'].unique()\n",
    "\n",
    "def extract_top_users(df_week, N=25):\n",
    "    top_retweeted = df_week.nlargest(N, \"retweeted_count\").reset_index(level=[\"user\"])\n",
    "    top_quoted = df_week.nlargest(N, \"quoted_count\").reset_index(level=[\"user\"])\n",
    "    most_tweets = df_week.nlargest(N, \"all_tweet_count\").reset_index(level=[\"user\"])\n",
    "    most_media_tweets = df_week.nlargest(N, \"media_tweet_count\").reset_index(level=[\"user\"])\n",
    "    most_quote_tweets = df_week.nlargest(N, \"quote_tweet_count\").reset_index(level=[\"user\"])\n",
    "    return (top_retweeted.merge(top_quoted, how=\"outer\")\n",
    "                         .merge(most_tweets, how=\"outer\")\n",
    "                         .merge(most_media_tweets, how=\"outer\")\n",
    "                         .merge(most_quote_tweets, how=\"outer\")).set_index(\"user\")\n",
    "\n",
    "columns = tweets.columns\n",
    "weekly_top_users = (tweets.groupby([\"WeekDate\", \"user\"])\n",
    "    .agg(\n",
    "        retweeted_count=('retweet_count', 'sum'), \n",
    "        quoted_count=('quote_count', 'sum'), \n",
    "        all_tweet_count=('datastore_id', 'count'),\n",
    "        media_tweet_count=('hasMedia', 'sum'),\n",
    "        quote_tweet_count=('quote_tweet', 'count')\n",
    "    )\n",
    "    .groupby(level=0, axis=0)\n",
    "    .apply(lambda df: extract_top_users(df))\n",
    "    #  Merge with user df and sort by week date, retweet count\n",
    "    .reset_index(level=[\"user\"])\n",
    "    .merge(df_users, how='inner', left_on=\"user\", right_index=True)\n",
    "    .set_index(\"user\", append=True)\n",
    "    .sort_values(by=['WeekDate', 'media_tweet_count'], ascending=[True, False]))\n",
    "\n",
    "weekly_top_users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(804, 16)"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "weekly_top_users.shape"
   ]
  },
  {
   "source": [
    "## Export"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "df_users.to_pickle(EXPORT_DIR + \"df_users.pickle\")\n",
    "retweet_df.to_pickle(EXPORT_DIR + \"df_retweets.pickle\")\n",
    "recent_tweet_df.to_pickle(EXPORT_DIR + \"df_recent_tweets.pickle\")\n",
    "old_tweet_df.to_pickle(EXPORT_DIR + \"df_old_tweets.pickle\")\n",
    "df_aggregated_by_hour.to_pickle(EXPORT_DIR + \"df_counts_by_hour.pickle\")\n",
    "crawled_terms_df.to_pickle(EXPORT_DIR + \"df_crawled_terms.pickle\")\n",
    "df_most_common_hashtags.to_pickle(EXPORT_DIR + \"df_most_common_hashtags.pickle\")\n",
    "df_most_common_tokens.to_pickle(EXPORT_DIR + \"df_most_common_tokens.pickle\")\n",
    "df_cooccurrence.to_pickle(EXPORT_DIR + \"df_cooccurrence.pickle\")\n",
    "df_media_with_tweets.to_pickle(EXPORT_DIR + \"df_media_with_tweets.pickle\")\n",
    "df_quote_tweets.to_pickle(EXPORT_DIR + \"df_quote_tweets.pickle\")\n",
    "weekly_top_tweets.to_pickle(EXPORT_DIR + \"df_weekly_top_tweets.pickle\")\n",
    "weekly_top_users.to_pickle(EXPORT_DIR + \"df_weekly_top_users.pickle\")\n",
    "\n",
    "with open(EXPORT_DIR + \"coverage_stats.pickle\", \"wb\") as f:\n",
    "    pickle.dump(coverage_stats, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users.to_pickle(EXPORT_DIR + \"df_users.pickle\")\n",
    "#retweet_df.to_pickle(EXPORT_DIR + \"df_retweets.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_media_with_tweets.to_pickle(EXPORT_DIR + \"df_media_with_tweets.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(EXPORT_DIR + \"coverage_stats.pickle\", \"wb\") as f:\n",
    "    pickle.dump(coverage_stats, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_top_tweets.to_pickle(EXPORT_DIR + \"df_weekly_top_tweets.pickle\")\n",
    "weekly_top_users.to_pickle(EXPORT_DIR + \"df_weekly_top_users.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "recent_tweet_df.to_pickle(EXPORT_DIR + \"df_recent_tweets.pickle\")\n",
    "old_tweet_df.to_pickle(EXPORT_DIR + \"df_old_tweets.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_top_tweets.to_pickle(EXPORT_DIR + \"df_weekly_top_tweets.pickle\")"
   ]
  }
 ]
}