{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "a0f90dcbb54bea4e60f894f8fd1d686cc0f74395b4029405cc9f13e0b975e641"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_utils import setup, load_tweet_df, load_media_df\n",
    "import pandas as pd\n",
    "\n",
    "setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATE = \"16-dec\"\n",
    "DATAFRAMES_DIR = \"../data/dataframes/{}/\".format(DATE)\n",
    "EXPORT_DIR = \"./data_export/url_stats/{}/\".format(DATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recent_tweets = pd.read_pickle(DATAFRAMES_DIR + \"df_recent_tweets.pickle\")"
   ]
  },
  {
   "source": [
    "# Top URLs in the dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import heapq\n",
    "url_map = defaultdict(lambda: {\n",
    "    \"tweet_ids\": set(),\n",
    "    \"aggregated_retweet_count\": 0,\n",
    "    \"aggregated_quote_count\": 0\n",
    "})\n",
    "\n",
    "total_tweet_count = 0\n",
    "total_retweet_count = 0\n",
    "total_quote_count = 0\n",
    "\n",
    "for tweet_id, urls, retweet_count, quote_count in df_recent_tweets[[\"urls\", \"retweet_count\", \"quote_count\"]].itertuples():\n",
    "    has_relevant_url = False\n",
    "    for url in urls:\n",
    "        if \"twitter.com/\" not in url:\n",
    "            has_relevant_url = True\n",
    "            url_map[url][\"tweet_ids\"].add(tweet_id)\n",
    "            url_map[url][\"aggregated_retweet_count\"] += retweet_count\n",
    "            url_map[url][\"aggregated_quote_count\"] += quote_count\n",
    "            total_retweet_count += retweet_count\n",
    "            total_quote_count += quote_count\n",
    "    if has_relevant_url:\n",
    "        total_tweet_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of tweets with URLs (excluding twitter.com URLs): 609,901\nUnique URLs shared: 155,064\nURL share retweet count: 2,847,863\nURL share quote count: 334,915\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of tweets with URLs (excluding twitter.com URLs): {:,}\".format(total_tweet_count))\n",
    "print(\"Unique URLs shared: {:,}\".format(len(url_map.keys())))\n",
    "print(\"URL share retweet count: {:,}\".format(total_retweet_count))\n",
    "print(\"URL share quote count: {:,}\".format(total_quote_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Top URLs in the dataset:\n49445 retweets from 19511 tweets - https://www.whitehouse.gov/presidential-actions/executive-order-imposing-certain-sanctions-event-foreign-interference-united-states-election/\n46758 retweets from 540 tweets - https://www.breitbart.com/2020-election/2020/11/23/poll-79-of-trump-voters-believe-election-was-stolen-through-illegal-voting-and-fraud/\n41078 retweets from 264 tweets - https://www.foxnews.com/opinion/tucker-carlson-2020-presidential-election-voter-fraud-dead-voters.amp\n39142 retweets from 719 tweets - https://www.breitbart.com/2020-election/2020/11/19/rudy-giuliani-the-case-for-election-fraud-being-made-by-american-patriots-in-both-parties/\n36198 retweets from 192 tweets - https://www.breitbart.com/2020-election/2020/11/07/republican-led-michigan-legislature-to-hold-hearings-on-election-fraud-claims/\n32156 retweets from 330 tweets - https://www.breitbart.com/2020-election/2020/11/17/california-2-charged-with-voter-fraud-allegedly-submitted-thousands-of-applications-on-behalf-of-homeless/\n26432 retweets from 1475 tweets - https://www.lawofficer.com/michigan-state-police-arrest-democratic-official-six-felony-charges-election-fraud/\n26293 retweets from 429 tweets - http://djt45.co/stopfraud\n25969 retweets from 64 tweets - https://thefederalist.com/2020/11/08/america-wont-trust-elections-until-the-voter-fraud-is-investigated/#.X6iHcjHduyR.twitter\n24659 retweets from 235 tweets - https://www.breitbart.com/politics/2020/11/30/donald-trump-calls-in-to-arizona-voter-fraud-hearing-were-fighting-back/\n"
     ]
    }
   ],
   "source": [
    "def top_urls_by_retweet_count(url_map, N = 10):\n",
    "    for url in heapq.nlargest(N, url_map, key=lambda x: url_map.get(x)[\"aggregated_retweet_count\"]):\n",
    "        url_stats = url_map.get(url)\n",
    "        tweet_count = len(url_stats[\"tweet_ids\"])\n",
    "        retweet_count = url_stats[\"aggregated_retweet_count\"]\n",
    "        print(\"{} retweets from {} tweets - {}\".format(retweet_count, tweet_count, url))\n",
    "\n",
    "def transform_url_map(url_map, filter_fn=lambda x: x, map_key=lambda x: x):\n",
    "    new_map = {}\n",
    "    for key, val in url_map.items():\n",
    "        if filter_fn(key):\n",
    "            mapped_key = map_key(key)\n",
    "            if (mapped_key in new_map):\n",
    "                existing_entry = new_map[mapped_key]\n",
    "                existing_entry[\"tweet_ids\"].update(val[\"tweet_ids\"])\n",
    "                existing_entry[\"aggregated_retweet_count\"] += val[\"aggregated_retweet_count\"]\n",
    "                existing_entry[\"aggregated_quote_count\"] += val[\"aggregated_quote_count\"]\n",
    "                new_map[mapped_key] = existing_entry\n",
    "            else:\n",
    "                new_map[mapped_key] = val.copy()\n",
    "\n",
    "    return new_map\n",
    "\n",
    "print(\"Top URLs in the dataset:\")\n",
    "top_urls_by_retweet_count(url_map)\n"
   ]
  },
  {
   "source": [
    "## Top Domains in the dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Unique domains in the dataset: 12,634\nTop domains in the dataset:\n210320 retweets from 10184 tweets - breitbart.com\n149799 retweets from 2614 tweets - pscp.tv\n105089 retweets from 22853 tweets - thegatewaypundit.com\n97824 retweets from 3380 tweets - justthenews.com\n97080 retweets from 5264 tweets - thefederalist.com\n93279 retweets from 82421 tweets - youtu.be\n86205 retweets from 7914 tweets - foxnews.com\n73007 retweets from 3921 tweets - oann.com\n72211 retweets from 38 tweets - hann.it\n52450 retweets from 1022 tweets - djhjmedia.com\n"
     ]
    }
   ],
   "source": [
    "from urllib.parse import parse_qs, urlencode, urlparse\n",
    "\n",
    "def map_to_domain(url):\n",
    "    parsed = urlparse(url)\n",
    "\n",
    "    return parsed.netloc.replace(\"www.\", \"\").lower()\n",
    "\n",
    "domain_url_map = transform_url_map(url_map, map_key=map_to_domain)\n",
    "print(\"Unique domains in the dataset: {:,}\".format(len(domain_url_map.keys())))\n",
    "print(\"Top domains in the dataset:\")\n",
    "\n",
    "top_urls_by_retweet_count(domain_url_map)"
   ]
  },
  {
   "source": [
    "## Top YouTube URLs in the dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Deleted URL params after normalizing Youtube URLs {'utm_campaign', 'view_as', 'utm_medium', 'itct', 't', 'PC', 'list', 'utm_term', 'redir_token', 'bsft_lx', 'v', 'rootVe', 'has_verified', 'persist_app', 'ebc', 'ab_channel', '__s', 'bsft_eid', 'd', 'bsft_uid', 'search_query', 'start_radio', 'authuser', 'app', 'event', 'html_redirect', 'bsft_mid', 'zarsrc', 'bsft_utid', 'mid', 'attr_tag', 'utm_name', 'bsft_link_id', 'playnext', 'sub_confirmation', 'reload', 'utm_source', 'FORM', 'amp;feature', 'bsft_tv', 'feature', 'isappinstalled', 'disable_polymer', 'index', 'fbclid', 'time_continue', 'bsft_clkid', 'from', 'q', 'noapp', 'id', 'bsft_aaid', 'bsft_mime_type', 'autoplay', 'bsft_ek', 'lc', 'vl', 'pbjreload', 'utm_content'}\n\nUnique Youtube URLs in the dataset: 14,051\nTop Youtube URLs in the dataset:\n13094 retweets from 25 tweets - https://youtu.be/LPdD8Cd5PGI\n11909 retweets from 92 tweets - https://youtu.be/psGpIuNh_dU\n7271 retweets from 436 tweets - https://youtu.be/w7vKBiPeyz4\n5234 retweets from 115 tweets - https://youtu.be/QNN9I0xxZRE\n4739 retweets from 337 tweets - https://youtu.be/96-BQaIVOpc\n3819 retweets from 32 tweets - https://youtu.be/bYTa1AMLJxY\n2495 retweets from 674 tweets - https://youtu.be/Ztu5Y5obWPk\n2258 retweets from 1462 tweets - https://youtu.be/p2MkvWh7poY\n1605 retweets from 150 tweets - https://youtu.be/VgMPDnWunqs\n1407 retweets from 223 tweets - https://youtu.be/g9_SgYJnbKo\n"
     ]
    }
   ],
   "source": [
    "deleted_url_params = set()\n",
    "\n",
    "def detect_youtube_url(url):\n",
    "    parsed = urlparse(url)\n",
    "    return \"youtu.be\" in parsed.netloc or \"youtube.com\" in parsed.netloc\n",
    "\n",
    "def normalize_youtube_url(url):\n",
    "    parsed = urlparse(url)\n",
    "    parsed = parsed._replace()\n",
    "    query_params = parse_qs(parsed.query)\n",
    "    if (parsed.path == '/watch' and \"v\" in query_params):\n",
    "        updated_path = '/' + query_params[\"v\"][0]\n",
    "        del query_params[\"v\"]\n",
    "        parsed = parsed._replace(path=updated_path)\n",
    "    deleted_url_params.update(query_params.keys())\n",
    "    query_params = {}\n",
    "    updated_query = urlencode(query_params, doseq=True)\n",
    "    parsed = parsed._replace(scheme='https', netloc='youtu.be', query=updated_query)\n",
    "    return parsed.geturl()\n",
    "\n",
    "youtube_url_map = transform_url_map(\n",
    "    url_map, \n",
    "    filter_fn=detect_youtube_url,\n",
    "    map_key=normalize_youtube_url\n",
    ")\n",
    "\n",
    "print(\"Deleted URL params after normalizing Youtube URLs\", deleted_url_params)\n",
    "\n",
    "print()\n",
    "print(\"Unique Youtube URLs in the dataset: {:,}\".format(len(youtube_url_map.keys())))\n",
    "print(\"Top Youtube URLs in the dataset:\")\n",
    "top_urls_by_retweet_count(youtube_url_map)"
   ]
  },
  {
   "source": [
    "# Top Media in the dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nIndex: 201461 entries, 5633333740437504 to 4895905840889856\nData columns (total 50 columns):\n #   Column                      Non-Null Count   Dtype           \n---  ------                      --------------   -----           \n 0   type                        201461 non-null  object          \n 1   media_id                    201461 non-null  object          \n 2   media_url                   201461 non-null  object          \n 3   tweet_id                    201461 non-null  object          \n 4   urls                        201209 non-null  object          \n 5   hasMedia                    201209 non-null  object          \n 6   hashtags                    201209 non-null  object          \n 7   retweet_count               201461 non-null  int32           \n 8   quote_count                 201461 non-null  int32           \n 9   user                        201209 non-null  object          \n 10  text                        201209 non-null  object          \n 11  quote_tweet                 94866 non-null   object          \n 12  timestamp                   201209 non-null  object          \n 13  tokens                      201209 non-null  object          \n 14  election fraud              201461 non-null  Sparse[int64, 0]\n 15  voter fraud                 201461 non-null  Sparse[int64, 0]\n 16  #voterfraud                 201461 non-null  Sparse[int64, 0]\n 17  #stopthesteal               201461 non-null  Sparse[int64, 0]\n 18  #ballotharvesting           201461 non-null  Sparse[int64, 0]\n 19  ballot fraud                201461 non-null  Sparse[int64, 0]\n 20  #electionfraud              201461 non-null  Sparse[int64, 0]\n 21  #electioninterference       201461 non-null  Sparse[int64, 0]\n 22  ballot harvesting           201461 non-null  Sparse[int64, 0]\n 23  election interference       201461 non-null  Sparse[int64, 0]\n 24  #electiontampering          201461 non-null  Sparse[int64, 0]\n 25  #cheatingdemocrats          201461 non-null  Sparse[int64, 0]\n 26  election tampering          201461 non-null  Sparse[int64, 0]\n 27  democrats cheat             201461 non-null  Sparse[int64, 0]\n 28  #voterfraudisreal           201461 non-null  Sparse[int64, 0]\n 29  cheating democrats          201461 non-null  Sparse[int64, 0]\n 30  #gopvoterfraud              201461 non-null  Sparse[int64, 0]\n 31  destroyed ballots           201461 non-null  Sparse[int64, 0]\n 32  stolen ballots              201461 non-null  Sparse[int64, 0]\n 33  #ballotfraud                201461 non-null  Sparse[int64, 0]\n 34  discarded ballots           201461 non-null  Sparse[int64, 0]\n 35  hacked voting machine       201461 non-null  Sparse[int64, 0]\n 36  pre-filled ballot           201461 non-null  Sparse[int64, 0]\n 37  harvest ballot              201461 non-null  Sparse[int64, 0]\n 38  #stopvoterfraud             201461 non-null  Sparse[int64, 0]\n 39  #democratvoterfraud         201461 non-null  Sparse[int64, 0]\n 40  #ballotvoterfraud           201461 non-null  Sparse[int64, 0]\n 41  #nomailinvoting             201461 non-null  Sparse[int64, 0]\n 42  #ilhanomarballotharvesting  201461 non-null  Sparse[int64, 0]\n 43  vote by mail fraud          201461 non-null  Sparse[int64, 0]\n 44  #mailinvoterfraud           201461 non-null  Sparse[int64, 0]\n 45  #votebymailfraud            201461 non-null  Sparse[int64, 0]\n 46  #ilhanomarvoterfraud        201461 non-null  Sparse[int64, 0]\n 47  #stopgopvoterfraud          201461 non-null  Sparse[int64, 0]\n 48  #discardedballots           201461 non-null  Sparse[int64, 0]\n 49  #hackedvotingmachines       201461 non-null  Sparse[int64, 0]\ndtypes: Sparse[int64, 0](36), int32(2), object(12)\nmemory usage: 32.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df_media_with_tweets = pd.read_pickle(DATAFRAMES_DIR + 'df_media_with_tweets.pickle')\n",
    "df_media_with_tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1325868287020970000    175\n",
       "1320106466028769282    162\n",
       "1324507941987405826    142\n",
       "1326595916002856963    132\n",
       "1329720320555581441    109\n",
       "                      ... \n",
       "1325487004579082242      1\n",
       "1333236566576091136      1\n",
       "1327929991007514625      1\n",
       "1331722326552039426      1\n",
       "1324151588387196930      1\n",
       "Name: media_id, Length: 196517, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df_media_with_tweets['media_id'].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2020-10-23 17:00:33+00:00\n2020-12-16 12:28:05+00:00\n(201209, 9)\nIndex(['media_url', 'media_id', 'tweet_id', 'hashtags', 'user', 'type',\n       'retweet_count', 'quote_count', 'timestamp'],\n      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_media_with_tweets.shape\n",
    "\n",
    "for_export = df_media_with_tweets[[\n",
    "    'media_url', 'media_id', 'tweet_id', 'hashtags', 'user', 'type', 'retweet_count', 'quote_count', 'timestamp'\n",
    "]]\n",
    "\n",
    "for_export['timestamp'] = pd.to_datetime(for_export['timestamp'])\n",
    "for_export = for_export[for_export['timestamp'] > '2020-10-23 00:00:00']\n",
    "print(for_export['timestamp'].min())\n",
    "print(for_export['timestamp'].max())\n",
    "print(for_export.shape)\n",
    "print(for_export.columns)\n",
    "for_export.head()\n",
    "for_export.to_csv(\"media_joined_with_tweets-{}.csv\".format(DATE), index_label=\"datastore_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 201209 entries, 0 to 201208\nData columns (total 10 columns):\n #   Column         Non-Null Count   Dtype \n---  ------         --------------   ----- \n 0   datastore_id   201209 non-null  int64 \n 1   media_url      201209 non-null  object\n 2   media_id       201209 non-null  int64 \n 3   tweet_id       201209 non-null  int64 \n 4   hashtags       201209 non-null  object\n 5   user           201209 non-null  int64 \n 6   type           201209 non-null  object\n 7   retweet_count  201209 non-null  int64 \n 8   quote_count    201209 non-null  int64 \n 9   timestamp      201209 non-null  object\ndtypes: int64(6), object(4)\nmemory usage: 15.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# Test export\n",
    "df = pd.read_csv(\"media_joined_with_tweets-{}.csv\".format(DATE))\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "19400 retweets: http://pbs.twimg.com/media/EmHTacqXgAAL7Zo.jpg\n17497 retweets: http://pbs.twimg.com/media/Enw48WQUUAUl01f.jpg\n16804 retweets: http://pbs.twimg.com/amplify_video_thumb/1324105823845523456/img/2z47IGTqb_gZij3r.jpg\n15526 retweets: http://pbs.twimg.com/media/EmAFt6BUcAAcs5r.jpg\n12341 retweets: http://pbs.twimg.com/ext_tw_video_thumb/1324476554446069763/pu/img/z-GoJ3__Ctp5WZpa.jpg\n12336 retweets: http://pbs.twimg.com/ext_tw_video_thumb/1324811238682013704/pu/img/eb79SStIIBfEfMcN.jpg\n11012 retweets: http://pbs.twimg.com/media/EmF9szQXUAQ9-KL.jpg\n10701 retweets: http://pbs.twimg.com/media/Emg71EpXUAYup9Z.jpg\n9294 retweets: http://pbs.twimg.com/media/EmACdkyX0AQ7bDO.png\n8853 retweets: http://pbs.twimg.com/media/Eo4KLDyXEAIy5Dl.jpg\n8527 retweets: http://pbs.twimg.com/media/EmFpwPFXYAI_06X.jpg\n7951 retweets: http://pbs.twimg.com/ext_tw_video_thumb/1324652359935352832/pu/img/--NEuAQfXmi8mupk.jpg\n7683 retweets: http://pbs.twimg.com/amplify_video_thumb/1325130145477373952/img/43S-cxrjXV10qOKd.jpg\n7532 retweets: http://pbs.twimg.com/ext_tw_video_thumb/1321854305163448320/pu/img/qCHkjziteY0frb5e.jpg\n7298 retweets: http://pbs.twimg.com/media/EntKYndXYAAVWV0.jpg\n6543 retweets: http://pbs.twimg.com/ext_tw_video_thumb/1336019912116989952/pu/img/V4tWfCAPqoOlwyOQ.jpg\n6505 retweets: http://pbs.twimg.com/ext_tw_video_thumb/1330199656450699268/pu/img/IZo0fsrltgpXsbwl.jpg\n6300 retweets: http://pbs.twimg.com/ext_tw_video_thumb/1326978765805801474/pu/img/GyQOd_3A-LoxoECy.jpg\n6068 retweets: http://pbs.twimg.com/media/EmLUO-iW0AIlJSt.jpg\n6068 retweets: http://pbs.twimg.com/media/EmLUPKCXYAEsPhT.jpg\n6047 retweets: http://pbs.twimg.com/ext_tw_video_thumb/1329618204067393537/pu/img/D-jRCobhsZded5Yw.jpg\n5778 retweets: http://pbs.twimg.com/ext_tw_video_thumb/1324060027301302273/pu/img/H3nPfo7k1XTPG3E0.jpg\n5547 retweets: http://pbs.twimg.com/media/El9VrRQXIAI201z.jpg\n5544 retweets: http://pbs.twimg.com/amplify_video_thumb/1335411584156438530/img/onMgh4s7pZeOj4ib.jpg\n5382 retweets: http://pbs.twimg.com/media/EmG42iCWMAAOn5D.jpg\n"
     ]
    }
   ],
   "source": [
    "def top_media_by_retweet_count(df_media_with_tweets, N = 25):\n",
    "    for media_id, media in df_media_with_tweets.nlargest(N, ['retweet_count']).iterrows():\n",
    "        retweet_count = media[\"retweet_count\"]\n",
    "        media_url = media[\"media_url\"]\n",
    "        print(\"{} retweets: {}\".format(retweet_count, media_url))\n",
    "\n",
    "top_media_by_retweet_count(df_media_with_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "196517"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "import numpy as np\n",
    "len(np.unique(df_media_with_tweets['media_url']))"
   ]
  },
  {
   "source": [
    "## Export to JSON"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def serialize_sets(obj):\n",
    "    if isinstance(obj, set):\n",
    "        return list(obj)\n",
    "\n",
    "    return obj\n",
    "\n",
    "with open(EXPORT_DIR + \"youtube_urls.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(youtube_url_map, f, sort_keys=True, indent=2, default=serialize_sets)\n",
    "\n",
    "with open(EXPORT_DIR + \"domains.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(domain_url_map, f, sort_keys=True, indent=2, default=serialize_sets)\n",
    "\n",
    "with open(EXPORT_DIR + \"all_urls.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(url_map, f, sort_keys=True, indent=2, default=serialize_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(EXPORT_DIR + \"expanded_url_map.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    expanded_map = json.load(url_map, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_map"
   ]
  }
 ]
}