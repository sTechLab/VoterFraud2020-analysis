{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('voter-fraud': conda)",
   "metadata": {
    "interpreter": {
     "hash": "a0f90dcbb54bea4e60f894f8fd1d686cc0f74395b4029405cc9f13e0b975e641"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_utils import setup, load_tweet_df, load_media_df\n",
    "import pandas as pd\n",
    "\n",
    "setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATE = \"16-dec\"\n",
    "DATAFRAMES_DIR = \"../data/dataframes/{}/\".format(DATE)\n",
    "EXPORT_DIR = \"./data_export/url_stats/{}/\".format(DATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recent_tweets = pd.read_pickle(DATAFRAMES_DIR + \"df_recent_tweets.pickle\")"
   ]
  },
  {
   "source": [
    "# Top URLs in the dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import heapq\n",
    "url_map = defaultdict(lambda: {\n",
    "    \"tweet_ids\": set(),\n",
    "    \"aggregated_retweet_count\": 0,\n",
    "    \"aggregated_quote_count\": 0\n",
    "})\n",
    "\n",
    "total_tweet_count = 0\n",
    "total_retweet_count = 0\n",
    "total_quote_count = 0\n",
    "\n",
    "for tweet_id, urls, retweet_count, quote_count in df_recent_tweets[[\"urls\", \"retweet_count\", \"quote_count\"]].itertuples():\n",
    "    has_relevant_url = False\n",
    "    for url in urls:\n",
    "        if \"twitter.com/\" not in url:\n",
    "            has_relevant_url = True\n",
    "            url_map[url][\"tweet_ids\"].add(tweet_id)\n",
    "            url_map[url][\"aggregated_retweet_count\"] += retweet_count\n",
    "            url_map[url][\"aggregated_quote_count\"] += quote_count\n",
    "            total_retweet_count += retweet_count\n",
    "            total_quote_count += quote_count\n",
    "    if has_relevant_url:\n",
    "        total_tweet_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of tweets with URLs (excluding twitter.com URLs): 609,901\nUnique URLs shared: 155,064\nURL share retweet count: 2,847,863\nURL share quote count: 334,915\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of tweets with URLs (excluding twitter.com URLs): {:,}\".format(total_tweet_count))\n",
    "print(\"Unique URLs shared: {:,}\".format(len(url_map.keys())))\n",
    "print(\"URL share retweet count: {:,}\".format(total_retweet_count))\n",
    "print(\"URL share quote count: {:,}\".format(total_quote_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Top URLs in the dataset:\n49445 retweets from 19511 tweets - https://www.whitehouse.gov/presidential-actions/executive-order-imposing-certain-sanctions-event-foreign-interference-united-states-election/\n46758 retweets from 540 tweets - https://www.breitbart.com/2020-election/2020/11/23/poll-79-of-trump-voters-believe-election-was-stolen-through-illegal-voting-and-fraud/\n41078 retweets from 264 tweets - https://www.foxnews.com/opinion/tucker-carlson-2020-presidential-election-voter-fraud-dead-voters.amp\n39142 retweets from 719 tweets - https://www.breitbart.com/2020-election/2020/11/19/rudy-giuliani-the-case-for-election-fraud-being-made-by-american-patriots-in-both-parties/\n36198 retweets from 192 tweets - https://www.breitbart.com/2020-election/2020/11/07/republican-led-michigan-legislature-to-hold-hearings-on-election-fraud-claims/\n32156 retweets from 330 tweets - https://www.breitbart.com/2020-election/2020/11/17/california-2-charged-with-voter-fraud-allegedly-submitted-thousands-of-applications-on-behalf-of-homeless/\n26432 retweets from 1475 tweets - https://www.lawofficer.com/michigan-state-police-arrest-democratic-official-six-felony-charges-election-fraud/\n26293 retweets from 429 tweets - http://djt45.co/stopfraud\n25969 retweets from 64 tweets - https://thefederalist.com/2020/11/08/america-wont-trust-elections-until-the-voter-fraud-is-investigated/#.X6iHcjHduyR.twitter\n24659 retweets from 235 tweets - https://www.breitbart.com/politics/2020/11/30/donald-trump-calls-in-to-arizona-voter-fraud-hearing-were-fighting-back/\n"
     ]
    }
   ],
   "source": [
    "def top_urls_by_retweet_count(url_map, N = 10):\n",
    "    for url in heapq.nlargest(N, url_map, key=lambda x: url_map.get(x)[\"aggregated_retweet_count\"]):\n",
    "        url_stats = url_map.get(url)\n",
    "        tweet_count = len(url_stats[\"tweet_ids\"])\n",
    "        retweet_count = url_stats[\"aggregated_retweet_count\"]\n",
    "        print(\"{} retweets from {} tweets - {}\".format(retweet_count, tweet_count, url))\n",
    "\n",
    "def transform_url_map(url_map, filter_fn=lambda x: x, map_key=lambda x: x):\n",
    "    new_map = {}\n",
    "    for key, val in url_map.items():\n",
    "        if filter_fn(key):\n",
    "            mapped_key = map_key(key)\n",
    "            if (mapped_key in new_map):\n",
    "                existing_entry = new_map[mapped_key]\n",
    "                existing_entry[\"tweet_ids\"].update(val[\"tweet_ids\"])\n",
    "                existing_entry[\"aggregated_retweet_count\"] += val[\"aggregated_retweet_count\"]\n",
    "                existing_entry[\"aggregated_quote_count\"] += val[\"aggregated_quote_count\"]\n",
    "                new_map[mapped_key] = existing_entry\n",
    "            else:\n",
    "                new_map[mapped_key] = val.copy()\n",
    "\n",
    "    return new_map\n",
    "\n",
    "print(\"Top URLs in the dataset:\")\n",
    "top_urls_by_retweet_count(url_map)\n"
   ]
  },
  {
   "source": [
    "## Top Domains in the dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Unique domains in the dataset: 12,634\nTop domains in the dataset:\n210320 retweets from 10184 tweets - breitbart.com\n149799 retweets from 2614 tweets - pscp.tv\n105089 retweets from 22853 tweets - thegatewaypundit.com\n97824 retweets from 3380 tweets - justthenews.com\n97080 retweets from 5264 tweets - thefederalist.com\n93279 retweets from 82421 tweets - youtu.be\n86205 retweets from 7914 tweets - foxnews.com\n73007 retweets from 3921 tweets - oann.com\n72211 retweets from 38 tweets - hann.it\n52450 retweets from 1022 tweets - djhjmedia.com\n"
     ]
    }
   ],
   "source": [
    "from urllib.parse import parse_qs, urlencode, urlparse\n",
    "\n",
    "def map_to_domain(url):\n",
    "    parsed = urlparse(url)\n",
    "\n",
    "    return parsed.netloc.replace(\"www.\", \"\").lower()\n",
    "\n",
    "domain_url_map = transform_url_map(url_map, map_key=map_to_domain)\n",
    "print(\"Unique domains in the dataset: {:,}\".format(len(domain_url_map.keys())))\n",
    "print(\"Top domains in the dataset:\")\n",
    "\n",
    "top_urls_by_retweet_count(domain_url_map)"
   ]
  },
  {
   "source": [
    "## Top YouTube URLs in the dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Deleted URL params after normalizing Youtube URLs {'utm_campaign', 'view_as', 'utm_medium', 'itct', 't', 'PC', 'list', 'utm_term', 'redir_token', 'bsft_lx', 'v', 'rootVe', 'has_verified', 'persist_app', 'ebc', 'ab_channel', '__s', 'bsft_eid', 'd', 'bsft_uid', 'search_query', 'start_radio', 'authuser', 'app', 'event', 'html_redirect', 'bsft_mid', 'zarsrc', 'bsft_utid', 'mid', 'attr_tag', 'utm_name', 'bsft_link_id', 'playnext', 'sub_confirmation', 'reload', 'utm_source', 'FORM', 'amp;feature', 'bsft_tv', 'feature', 'isappinstalled', 'disable_polymer', 'index', 'fbclid', 'time_continue', 'bsft_clkid', 'from', 'q', 'noapp', 'id', 'bsft_aaid', 'bsft_mime_type', 'autoplay', 'bsft_ek', 'lc', 'vl', 'pbjreload', 'utm_content'}\n\nUnique Youtube URLs in the dataset: 14,051\nTop Youtube URLs in the dataset:\n13094 retweets from 25 tweets - https://youtu.be/LPdD8Cd5PGI\n11909 retweets from 92 tweets - https://youtu.be/psGpIuNh_dU\n7271 retweets from 436 tweets - https://youtu.be/w7vKBiPeyz4\n5234 retweets from 115 tweets - https://youtu.be/QNN9I0xxZRE\n4739 retweets from 337 tweets - https://youtu.be/96-BQaIVOpc\n3819 retweets from 32 tweets - https://youtu.be/bYTa1AMLJxY\n2495 retweets from 674 tweets - https://youtu.be/Ztu5Y5obWPk\n2258 retweets from 1462 tweets - https://youtu.be/p2MkvWh7poY\n1605 retweets from 150 tweets - https://youtu.be/VgMPDnWunqs\n1407 retweets from 223 tweets - https://youtu.be/g9_SgYJnbKo\n"
     ]
    }
   ],
   "source": [
    "deleted_url_params = set()\n",
    "\n",
    "def detect_youtube_url(url):\n",
    "    parsed = urlparse(url)\n",
    "    return \"youtu.be\" in parsed.netloc or \"youtube.com\" in parsed.netloc\n",
    "\n",
    "def normalize_youtube_url(url):\n",
    "    parsed = urlparse(url)\n",
    "    parsed = parsed._replace()\n",
    "    query_params = parse_qs(parsed.query)\n",
    "    if (parsed.path == '/watch' and \"v\" in query_params):\n",
    "        updated_path = '/' + query_params[\"v\"][0]\n",
    "        del query_params[\"v\"]\n",
    "        parsed = parsed._replace(path=updated_path)\n",
    "    deleted_url_params.update(query_params.keys())\n",
    "    query_params = {}\n",
    "    updated_query = urlencode(query_params, doseq=True)\n",
    "    parsed = parsed._replace(scheme='https', netloc='youtu.be', query=updated_query)\n",
    "    return parsed.geturl()\n",
    "\n",
    "youtube_url_map = transform_url_map(\n",
    "    url_map, \n",
    "    filter_fn=detect_youtube_url,\n",
    "    map_key=normalize_youtube_url\n",
    ")\n",
    "\n",
    "print(\"Deleted URL params after normalizing Youtube URLs\", deleted_url_params)\n",
    "\n",
    "print()\n",
    "print(\"Unique Youtube URLs in the dataset: {:,}\".format(len(youtube_url_map.keys())))\n",
    "print(\"Top Youtube URLs in the dataset:\")\n",
    "top_urls_by_retweet_count(youtube_url_map)"
   ]
  },
  {
   "source": [
    "# Top Media in the dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nIndex: 196517 entries, 1339030097194483712 to 1332824783738839040\nData columns (total 49 columns):\n #   Column                      Non-Null Count   Dtype           \n---  ------                      --------------   -----           \n 0   datastore_id                196517 non-null  object          \n 1   type                        196517 non-null  object          \n 2   media_id                    196517 non-null  object          \n 3   media_url                   196517 non-null  object          \n 4   urls                        196280 non-null  object          \n 5   hasMedia                    196280 non-null  object          \n 6   hashtags                    196280 non-null  object          \n 7   retweet_count               196517 non-null  int32           \n 8   quote_count                 196517 non-null  int32           \n 9   user                        196280 non-null  object          \n 10  quote_tweet                 93873 non-null   object          \n 11  timestamp                   196280 non-null  object          \n 12  tokens                      196280 non-null  object          \n 13  election fraud              196517 non-null  Sparse[int64, 0]\n 14  voter fraud                 196517 non-null  Sparse[int64, 0]\n 15  #voterfraud                 196517 non-null  Sparse[int64, 0]\n 16  #stopthesteal               196517 non-null  Sparse[int64, 0]\n 17  #ballotharvesting           196517 non-null  Sparse[int64, 0]\n 18  ballot fraud                196517 non-null  Sparse[int64, 0]\n 19  #electionfraud              196517 non-null  Sparse[int64, 0]\n 20  #electioninterference       196517 non-null  Sparse[int64, 0]\n 21  ballot harvesting           196517 non-null  Sparse[int64, 0]\n 22  election interference       196517 non-null  Sparse[int64, 0]\n 23  #electiontampering          196517 non-null  Sparse[int64, 0]\n 24  #cheatingdemocrats          196517 non-null  Sparse[int64, 0]\n 25  election tampering          196517 non-null  Sparse[int64, 0]\n 26  democrats cheat             196517 non-null  Sparse[int64, 0]\n 27  #voterfraudisreal           196517 non-null  Sparse[int64, 0]\n 28  cheating democrats          196517 non-null  Sparse[int64, 0]\n 29  #gopvoterfraud              196517 non-null  Sparse[int64, 0]\n 30  destroyed ballots           196517 non-null  Sparse[int64, 0]\n 31  stolen ballots              196517 non-null  Sparse[int64, 0]\n 32  #ballotfraud                196517 non-null  Sparse[int64, 0]\n 33  discarded ballots           196517 non-null  Sparse[int64, 0]\n 34  hacked voting machine       196517 non-null  Sparse[int64, 0]\n 35  pre-filled ballot           196517 non-null  Sparse[int64, 0]\n 36  harvest ballot              196517 non-null  Sparse[int64, 0]\n 37  #stopvoterfraud             196517 non-null  Sparse[int64, 0]\n 38  #democratvoterfraud         196517 non-null  Sparse[int64, 0]\n 39  #ballotvoterfraud           196517 non-null  Sparse[int64, 0]\n 40  #nomailinvoting             196517 non-null  Sparse[int64, 0]\n 41  #ilhanomarballotharvesting  196517 non-null  Sparse[int64, 0]\n 42  vote by mail fraud          196517 non-null  Sparse[int64, 0]\n 43  #mailinvoterfraud           196517 non-null  Sparse[int64, 0]\n 44  #votebymailfraud            196517 non-null  Sparse[int64, 0]\n 45  #ilhanomarvoterfraud        196517 non-null  Sparse[int64, 0]\n 46  #stopgopvoterfraud          196517 non-null  Sparse[int64, 0]\n 47  #discardedballots           196517 non-null  Sparse[int64, 0]\n 48  #hackedvotingmachines       196517 non-null  Sparse[int64, 0]\ndtypes: Sparse[int64, 0](36), int32(2), object(11)\nmemory usage: 29.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df_media_with_tweets = pd.read_pickle(DATAFRAMES_DIR + 'df_media_with_tweets.pickle')\n",
    "df_media_with_tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2020-10-23 17:00:33+00:00\n2020-12-16 12:28:05+00:00\n(196280, 6)\nIndex(['media_url', 'media_id', 'type', 'retweet_count', 'quote_count',\n       'timestamp'],\n      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_media_with_tweets.shape\n",
    "\n",
    "for_export = df_media_with_tweets[[\n",
    "    'media_url', 'media_id', 'type', 'retweet_count', 'quote_count', 'timestamp'\n",
    "]]\n",
    "\n",
    "for_export['timestamp'] = pd.to_datetime(for_export['timestamp'])\n",
    "for_export = for_export[for_export['timestamp'] > '2020-10-23 00:00:00']\n",
    "print(for_export['timestamp'].min())\n",
    "print(for_export['timestamp'].max())\n",
    "print(for_export.shape)\n",
    "print(for_export.columns)\n",
    "for_export.head()\n",
    "for_export.to_csv(\"media_joined_with_tweets-{}.csv\".format(DATE), index_label=\"tweet_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "19400 retweets: http://pbs.twimg.com/media/EmHTacqXgAAL7Zo.jpg\n17497 retweets: http://pbs.twimg.com/media/Enw48WQUUAUl01f.jpg\n16804 retweets: http://pbs.twimg.com/amplify_video_thumb/1324105823845523456/img/2z47IGTqb_gZij3r.jpg\n15526 retweets: http://pbs.twimg.com/media/EmAFt6BUcAAcs5r.jpg\n12341 retweets: http://pbs.twimg.com/ext_tw_video_thumb/1324476554446069763/pu/img/z-GoJ3__Ctp5WZpa.jpg\n12336 retweets: http://pbs.twimg.com/ext_tw_video_thumb/1324811238682013704/pu/img/eb79SStIIBfEfMcN.jpg\n11012 retweets: http://pbs.twimg.com/media/EmF9szQXUAQ9-KL.jpg\n10701 retweets: http://pbs.twimg.com/media/Emg71EpXUAYup9Z.jpg\n9294 retweets: http://pbs.twimg.com/media/EmACdkyX0AQ7bDO.png\n8853 retweets: http://pbs.twimg.com/media/Eo4KLDyXEAIy5Dl.jpg\n8527 retweets: http://pbs.twimg.com/media/EmFpwPFXYAI_06X.jpg\n7951 retweets: http://pbs.twimg.com/ext_tw_video_thumb/1324652359935352832/pu/img/--NEuAQfXmi8mupk.jpg\n7683 retweets: http://pbs.twimg.com/amplify_video_thumb/1325130145477373952/img/43S-cxrjXV10qOKd.jpg\n7532 retweets: http://pbs.twimg.com/ext_tw_video_thumb/1321854305163448320/pu/img/qCHkjziteY0frb5e.jpg\n7298 retweets: http://pbs.twimg.com/media/EntKYndXYAAVWV0.jpg\n6543 retweets: http://pbs.twimg.com/ext_tw_video_thumb/1336019912116989952/pu/img/V4tWfCAPqoOlwyOQ.jpg\n6505 retweets: http://pbs.twimg.com/ext_tw_video_thumb/1330199656450699268/pu/img/IZo0fsrltgpXsbwl.jpg\n6300 retweets: http://pbs.twimg.com/ext_tw_video_thumb/1326978765805801474/pu/img/GyQOd_3A-LoxoECy.jpg\n6068 retweets: http://pbs.twimg.com/media/EmLUO-iW0AIlJSt.jpg\n6068 retweets: http://pbs.twimg.com/media/EmLUPKCXYAEsPhT.jpg\n6047 retweets: http://pbs.twimg.com/ext_tw_video_thumb/1329618204067393537/pu/img/D-jRCobhsZded5Yw.jpg\n5778 retweets: http://pbs.twimg.com/ext_tw_video_thumb/1324060027301302273/pu/img/H3nPfo7k1XTPG3E0.jpg\n5547 retweets: http://pbs.twimg.com/media/El9VrRQXIAI201z.jpg\n5544 retweets: http://pbs.twimg.com/amplify_video_thumb/1335411584156438530/img/onMgh4s7pZeOj4ib.jpg\n5382 retweets: http://pbs.twimg.com/media/EmG42iCWMAAOn5D.jpg\n"
     ]
    }
   ],
   "source": [
    "def top_media_by_retweet_count(df_media_with_tweets, N = 25):\n",
    "    for media_id, media in df_media_with_tweets.nlargest(N, ['retweet_count']).iterrows():\n",
    "        retweet_count = media[\"retweet_count\"]\n",
    "        media_url = media[\"media_url\"]\n",
    "        print(\"{} retweets: {}\".format(retweet_count, media_url))\n",
    "\n",
    "top_media_by_retweet_count(df_media_with_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "196517"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "import numpy as np\n",
    "len(np.unique(df_media_with_tweets['media_url']))"
   ]
  },
  {
   "source": [
    "## Export to JSON"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def serialize_sets(obj):\n",
    "    if isinstance(obj, set):\n",
    "        return list(obj)\n",
    "\n",
    "    return obj\n",
    "\n",
    "with open(EXPORT_DIR + \"youtube_urls.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(youtube_url_map, f, sort_keys=True, indent=2, default=serialize_sets)\n",
    "\n",
    "with open(EXPORT_DIR + \"domains.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(domain_url_map, f, sort_keys=True, indent=2, default=serialize_sets)\n",
    "\n",
    "with open(EXPORT_DIR + \"all_urls.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(url_map, f, sort_keys=True, indent=2, default=serialize_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(EXPORT_DIR + \"expanded_url_map.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    expanded_map = json.load(url_map, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_map"
   ]
  }
 ]
}