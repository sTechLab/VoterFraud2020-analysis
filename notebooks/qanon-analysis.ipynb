{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('voter-fraud': conda)",
   "metadata": {
    "interpreter": {
     "hash": "a0f90dcbb54bea4e60f894f8fd1d686cc0f74395b4029405cc9f13e0b975e641"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_utils import setup\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from data_tools import load_parsed_data\n",
    "\n",
    "setup()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_hashtags = set(['qproofs', 'calmbeforethestorm', 'qanon', 'greatawakening', 'stqrm', 'cbts', 'wwg', 'wga', 'cabal', 'outoftheshadows', 'enjoytheshow', 'awake', 'thestorm', 'q', 'theshow' 'qproofs', 'calmbeforethestorm', 'qanon', 'greatawakening', 'stqrm', 'cbts', 'wwg', 'wga', 'cabal', 'outoftheshadows', 'enjoytheshow', 'neonrevolt', 'pizzagate', 'savethechildren', 'qmovie', 'patriqts', 'thegreatawakening', 'q', 'wwg1wga'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recent_tweets = pd.read_pickle(\"./df_recent_tweets_with_final_metrics.pickle\")\n",
    "#[[\"user_id\", \"user_active_status\", \"user_community\", \"hashtags\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Processed 0\n",
      "Processed 100000\n",
      "Processed 200000\n",
      "Processed 300000\n",
      "Processed 400000\n",
      "Processed 500000\n",
      "Processed 600000\n",
      "Processed 700000\n",
      "Processed 800000\n",
      "Processed 900000\n",
      "Processed 1000000\n",
      "Processed 1100000\n",
      "Processed 1200000\n",
      "Processed 1300000\n",
      "Processed 1400000\n",
      "Processed 1500000\n",
      "Processed 1600000\n",
      "Processed 1700000\n",
      "Processed 1800000\n",
      "Processed 1900000\n",
      "Processed 2000000\n",
      "Processed 2100000\n",
      "Processed 2200000\n",
      "Processed 2300000\n",
      "Processed 2400000\n",
      "Processed 2500000\n",
      "Processed 2600000\n",
      "Processed 2700000\n",
      "Processed 2800000\n",
      "Processed 2900000\n",
      "Processed 3000000\n",
      "Processed 3100000\n",
      "Processed 3200000\n",
      "Processed 3300000\n",
      "Processed 3400000\n",
      "Processed 3500000\n",
      "Processed 3600000\n",
      "Processed 3700000\n",
      "Processed 3800000\n",
      "Processed 3900000\n",
      "Processed 4000000\n",
      "Processed 4100000\n",
      "Processed 4200000\n",
      "Processed 4300000\n",
      "Processed 4400000\n",
      "Processed 4500000\n",
      "Processed 4600000\n",
      "Processed 4700000\n",
      "Processed 4800000\n",
      "Processed 4900000\n",
      "Processed 5000000\n",
      "Processed 5100000\n",
      "Processed 5200000\n",
      "Processed 5300000\n",
      "Processed 5400000\n",
      "Processed 5500000\n",
      "Processed 5600000\n",
      "Processed 5700000\n",
      "Processed 5800000\n",
      "Processed 5900000\n",
      "Processed 6000000\n",
      "Processed 6100000\n",
      "Processed 6200000\n",
      "Processed 6300000\n",
      "Processed 6400000\n",
      "Processed 6500000\n",
      "Processed 6600000\n",
      "Processed 6700000\n",
      "Processed 6800000\n",
      "Processed 6900000\n",
      "Processed 7000000\n",
      "Processed 7100000\n",
      "Processed 7200000\n",
      "Processed 7300000\n",
      "Processed 7400000\n",
      "Processed 7500000\n",
      "Processed 7600000\n"
     ]
    }
   ],
   "source": [
    "q_anon_users = defaultdict(lambda: {\n",
    "    \"tweets\": [],\n",
    "    \"user_active_status\": None,\n",
    "    \"user_community\": None\n",
    "})\n",
    "for i, tweet_id, hashtags, user_id, user_community, user_active_status in df_recent_tweets[[\"datastore_id\", \"hashtags\", \"user\", \"cluster\", \"author_active_status\"]].itertuples():\n",
    "    for hashtag in hashtags:\n",
    "        if (hashtag.lower() in Q_hashtags):\n",
    "            q_anon_users[user_id][\"tweets\"].append(tweet_id)\n",
    "            q_anon_users[user_id][\"user_active_status\"] = user_active_status\n",
    "            q_anon_users[user_id][\"user_community\"] = user_community\n",
    "            break\n",
    "    if (i % 100000 == 0):\n",
    "        print(\"Processed\", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Q anon users: 3,604\nQ anon tweets: 16,692\nSuspended users: 1,598\nCluster counts: [221, 354, 2392, 43, 14]\n"
     ]
    }
   ],
   "source": [
    "suspended_users = 0\n",
    "community_counts = [0] * 5\n",
    "na_community_counts = 0\n",
    "\n",
    "for user in q_anon_users.values():\n",
    "    user_community = user[\"user_community\"]\n",
    "    if (pd.notna(user_community)):\n",
    "        community_counts[user_community] += 1\n",
    "    else:\n",
    "        na_community_counts += 1\n",
    "    if (user[\"user_active_status\"] == \"suspended\"):\n",
    "        suspended_users += 1\n",
    "\n",
    "print(\"Q anon users: {:,}\".format(len(q_anon_users)))\n",
    "print(\"Q anon tweets: {:,}\".format(sum([len(user[\"tweets\"]) for user in q_anon_users.values()])))\n",
    "print(\"Suspended users: {:,}\".format(suspended_users))\n",
    "print(\"Cluster counts: {}\".format(community_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users_with_metrics = pd.read_pickle(\"./df_users_final_with_metrics.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading 1388621 json lines\n",
      "(7%): 100000 lines in ../data/16-dec/parsed_users.json processed (0.7239601612091064 sec)\n",
      "(14%): 200000 lines in ../data/16-dec/parsed_users.json processed (0.7170572280883789 sec)\n",
      "(22%): 300000 lines in ../data/16-dec/parsed_users.json processed (0.7579159736633301 sec)\n",
      "(29%): 400000 lines in ../data/16-dec/parsed_users.json processed (0.7270603179931641 sec)\n",
      "(36%): 500000 lines in ../data/16-dec/parsed_users.json processed (0.8404359817504883 sec)\n",
      "(43%): 600000 lines in ../data/16-dec/parsed_users.json processed (0.8477151393890381 sec)\n",
      "(50%): 700000 lines in ../data/16-dec/parsed_users.json processed (0.8460862636566162 sec)\n",
      "(58%): 800000 lines in ../data/16-dec/parsed_users.json processed (0.7989709377288818 sec)\n",
      "(65%): 900000 lines in ../data/16-dec/parsed_users.json processed (0.7584409713745117 sec)\n",
      "(72%): 1000000 lines in ../data/16-dec/parsed_users.json processed (0.8521640300750732 sec)\n",
      "(79%): 1100000 lines in ../data/16-dec/parsed_users.json processed (0.8586890697479248 sec)\n",
      "(86%): 1200000 lines in ../data/16-dec/parsed_users.json processed (0.8692221641540527 sec)\n",
      "(94%): 1300000 lines in ../data/16-dec/parsed_users.json processed (0.8875839710235596 sec)\n",
      "Done loading ../data/16-dec/parsed_users.json\n",
      "1388621 lines in ../data/16-dec/parsed_users.json processed (11.236581325531006 sec)\n"
     ]
    }
   ],
   "source": [
    "cast_cols = {\n",
    "    \"followed_cnts\": \"int32\",\n",
    "    \"friends_count\": \"int32\",\n",
    "    \"followers_count\": \"int32\",\n",
    "}\n",
    "\n",
    "df_users =  load_parsed_data(\n",
    "    \"../data/16-dec/parsed_users.json\",\n",
    "    cast_cols=cast_cols,\n",
    "    index_col=\"datastore_id\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Q terms\n",
      "{'neonrevolt', 'wwg', 'outoftheshadows', 'stqrm', 'greatawakening', 'enjoytheshow', 'cabal', 'cbts', 'calmbeforethestorm', 'wwg1wga', 'qproofs', 'qmovie', 'thestorm', 'theshowqproofs', 'wga', 'pizzagate', 'savethechildren', 'qanon', 'patriqts', 'thegreatawakening', 'awake'}\n",
      "Processed 0\n",
      "Processed 100000\n",
      "Processed 200000\n",
      "Processed 300000\n",
      "Processed 400000\n",
      "Processed 500000\n",
      "Processed 600000\n",
      "Processed 700000\n",
      "Processed 800000\n",
      "Processed 900000\n",
      "Processed 1000000\n",
      "Processed 1100000\n",
      "Processed 1200000\n",
      "Processed 1300000\n"
     ]
    }
   ],
   "source": [
    "Q_terms = (Q_hashtags - set([\"q\"]))\n",
    "\n",
    "print(\"Q terms\")\n",
    "print(Q_terms)\n",
    "\n",
    "q_anon_description_users = {}\n",
    "i = 0\n",
    "for datastore_id, description in df_users[\"description\"].items():\n",
    "    if (description is not None):\n",
    "        text = description.lower()\n",
    "        for term in Q_terms:\n",
    "            if (term in text):\n",
    "                q_anon_description_users[datastore_id] = {\n",
    "                    \"description\": description\n",
    "                }\n",
    "    if (i % 100000 == 0):\n",
    "        print(\"Processed\", i)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "32360"
      ]
     },
     "metadata": {},
     "execution_count": 114
    }
   ],
   "source": [
    "len(q_anon_description_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Users: 32,360\nSuspended users: 21,532\nCommunity counts: [475, 4597, 20703, 149, 120]\n"
     ]
    }
   ],
   "source": [
    "suspended_user_count = 0\n",
    "community_counts = [0] * 5\n",
    "\n",
    "for user_id in q_anon_description_users:\n",
    "    active_status = df_users_with_metrics[\"active_status\"].loc[user_id]\n",
    "    community = df_users_with_metrics[\"cluster\"].loc[user_id]\n",
    "    if (active_status == \"suspended\"):\n",
    "        suspended_user_count += 1\n",
    "    if (pd.notna(community)):\n",
    "        community_counts[community] += 1\n",
    "    \n",
    "\n",
    "print(\"Users: {:,}\".format(len(q_anon_description_users)))\n",
    "print(\"Suspended users: {:,}\".format(suspended_user_count))\n",
    "print(\"Community counts: {}\".format(community_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_users = set(q_anon_users.keys()).union(set(q_anon_description_users.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Users: 34,938\nSuspended users: 15,905\nCommunity counts: [0, 0, 22303, 0, 0]\nMissing user ids: {'1308582348859101186', '1260001609297408002'}\n"
     ]
    }
   ],
   "source": [
    "suspended_user_count = 0\n",
    "community_counts = [0] * 5\n",
    "missing_user_ids = set()\n",
    "\n",
    "for user_id in combined_users:\n",
    "    if (user_id in df_users_with_metrics.index):\n",
    "        community = df_users_with_metrics[\"cluster\"].loc[user_id]\n",
    "        if (pd.notna(community) and community == 2):\n",
    "            active_status = df_users_with_metrics[\"active_status\"].loc[user_id]\n",
    "            if (active_status == \"suspended\"):\n",
    "                suspended_user_count += 1\n",
    "            if (pd.notna(community)):\n",
    "                community_counts[community] += 1\n",
    "    else:\n",
    "        missing_user_ids.add(user_id)\n",
    "    \n",
    "\n",
    "print(\"Users: {:,}\".format(len(combined_users)))\n",
    "print(\"Suspended users: {:,}\".format(suspended_user_count))\n",
    "print(\"Community counts: {}\".format(community_counts))\n",
    "print(\"Missing user ids: {}\".format(missing_user_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}