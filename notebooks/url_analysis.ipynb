{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('voter-fraud': conda)",
   "metadata": {
    "interpreter": {
     "hash": "a0f90dcbb54bea4e60f894f8fd1d686cc0f74395b4029405cc9f13e0b975e641"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_utils import setup, load_tweet_df\n",
    "\n",
    "setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading 2696807 json lines\n",
      "(4%): 100000 lines in ../data/14-nov/parsed_tweets.json processed (1.796416997909546 sec)\n",
      "(7%): 200000 lines in ../data/14-nov/parsed_tweets.json processed (1.871419906616211 sec)\n",
      "(11%): 300000 lines in ../data/14-nov/parsed_tweets.json processed (2.2562928199768066 sec)\n",
      "(15%): 400000 lines in ../data/14-nov/parsed_tweets.json processed (1.9818439483642578 sec)\n",
      "(19%): 500000 lines in ../data/14-nov/parsed_tweets.json processed (2.2397468090057373 sec)\n",
      "(22%): 600000 lines in ../data/14-nov/parsed_tweets.json processed (2.4842288494110107 sec)\n",
      "(26%): 700000 lines in ../data/14-nov/parsed_tweets.json processed (2.7024729251861572 sec)\n",
      "(30%): 800000 lines in ../data/14-nov/parsed_tweets.json processed (1.3462560176849365 sec)\n",
      "(33%): 900000 lines in ../data/14-nov/parsed_tweets.json processed (3.212778091430664 sec)\n",
      "(37%): 1000000 lines in ../data/14-nov/parsed_tweets.json processed (1.3535559177398682 sec)\n",
      "(41%): 1100000 lines in ../data/14-nov/parsed_tweets.json processed (1.297184944152832 sec)\n",
      "(44%): 1200000 lines in ../data/14-nov/parsed_tweets.json processed (3.554036855697632 sec)\n",
      "(48%): 1300000 lines in ../data/14-nov/parsed_tweets.json processed (1.3101749420166016 sec)\n",
      "(52%): 1400000 lines in ../data/14-nov/parsed_tweets.json processed (1.346374273300171 sec)\n",
      "(56%): 1500000 lines in ../data/14-nov/parsed_tweets.json processed (4.115496873855591 sec)\n",
      "(59%): 1600000 lines in ../data/14-nov/parsed_tweets.json processed (1.301426887512207 sec)\n",
      "(63%): 1700000 lines in ../data/14-nov/parsed_tweets.json processed (1.3495469093322754 sec)\n",
      "(67%): 1800000 lines in ../data/14-nov/parsed_tweets.json processed (4.948567152023315 sec)\n",
      "(70%): 1900000 lines in ../data/14-nov/parsed_tweets.json processed (1.3368399143218994 sec)\n",
      "(74%): 2000000 lines in ../data/14-nov/parsed_tweets.json processed (1.4301402568817139 sec)\n",
      "(78%): 2100000 lines in ../data/14-nov/parsed_tweets.json processed (1.2934517860412598 sec)\n",
      "(82%): 2200000 lines in ../data/14-nov/parsed_tweets.json processed (1.298811912536621 sec)\n",
      "(85%): 2300000 lines in ../data/14-nov/parsed_tweets.json processed (5.581379175186157 sec)\n",
      "(89%): 2400000 lines in ../data/14-nov/parsed_tweets.json processed (1.3865277767181396 sec)\n",
      "(93%): 2500000 lines in ../data/14-nov/parsed_tweets.json processed (1.3926939964294434 sec)\n",
      "(96%): 2600000 lines in ../data/14-nov/parsed_tweets.json processed (1.386944055557251 sec)\n",
      "Done loading ../data/14-nov/parsed_tweets.json\n",
      "2696807 lines in ../data/14-nov/parsed_tweets.json processed (56.82452702522278 sec)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2696807 entries, 0 to 2696806\n",
      "Data columns (total 45 columns):\n",
      " #   Column                      Dtype          \n",
      "---  ------                      -----          \n",
      " 0   datastore_id                object         \n",
      " 1   hashtags                    object         \n",
      " 2   urls                        object         \n",
      " 3   hasMedia                    bool           \n",
      " 4   quote_tweet                 object         \n",
      " 5   retweet_count               int32          \n",
      " 6   timestamp                   object         \n",
      " 7   quote_count                 int32          \n",
      " 8   user                        object         \n",
      " 9   tokens                      object         \n",
      " 10  voter fraud                 Sparse[int8, 0]\n",
      " 11  #electionfraud              Sparse[int8, 0]\n",
      " 12  ballot fraud                Sparse[int8, 0]\n",
      " 13  #voterfraud                 Sparse[int8, 0]\n",
      " 14  #stopthesteal               Sparse[int8, 0]\n",
      " 15  stolen ballots              Sparse[int8, 0]\n",
      " 16  election fraud              Sparse[int8, 0]\n",
      " 17  ballot harvesting           Sparse[int8, 0]\n",
      " 18  #electioninterference       Sparse[int8, 0]\n",
      " 19  #cheatingdemocrats          Sparse[int8, 0]\n",
      " 20  election interference       Sparse[int8, 0]\n",
      " 21  #ballotfraud                Sparse[int8, 0]\n",
      " 22  cheating democrats          Sparse[int8, 0]\n",
      " 23  #electiontampering          Sparse[int8, 0]\n",
      " 24  #ballotharvesting           Sparse[int8, 0]\n",
      " 25  #voterfraudisreal           Sparse[int8, 0]\n",
      " 26  destroyed ballots           Sparse[int8, 0]\n",
      " 27  democrats cheat             Sparse[int8, 0]\n",
      " 28  #stopvoterfraud             Sparse[int8, 0]\n",
      " 29  #ballotvoterfraud           Sparse[int8, 0]\n",
      " 30  election tampering          Sparse[int8, 0]\n",
      " 31  #democratvoterfraud         Sparse[int8, 0]\n",
      " 32  discarded ballots           Sparse[int8, 0]\n",
      " 33  vote by mail fraud          Sparse[int8, 0]\n",
      " 34  harvest ballot              Sparse[int8, 0]\n",
      " 35  #gopvoterfraud              Sparse[int8, 0]\n",
      " 36  #nomailinvoting             Sparse[int8, 0]\n",
      " 37  #votebymailfraud            Sparse[int8, 0]\n",
      " 38  #mailinvoterfraud           Sparse[int8, 0]\n",
      " 39  pre-filled ballot           Sparse[int8, 0]\n",
      " 40  hacked voting machine       Sparse[int8, 0]\n",
      " 41  #ilhanomarballotharvesting  Sparse[int8, 0]\n",
      " 42  #ilhanomarvoterfraud        Sparse[int8, 0]\n",
      " 43  #hackedvotingmachines       Sparse[int8, 0]\n",
      " 44  #discardedballots           Sparse[int8, 0]\n",
      "dtypes: Sparse[int8, 0](35), bool(1), int32(2), object(7)\n",
      "memory usage: 173.9+ MB\n"
     ]
    }
   ],
   "source": [
    "tweet_df, recent_tweet_df = load_tweet_df()\n",
    "\n",
    "tweet_df.info()"
   ]
  },
  {
   "source": [
    "# Top URLs in the dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import heapq\n",
    "url_map = defaultdict(lambda: {\n",
    "    \"tweet_ids\": set(),\n",
    "    \"retweet_count\": 0,\n",
    "    \"quote_count\": 0\n",
    "})\n",
    "\n",
    "total_tweet_count = 0\n",
    "total_retweet_count = 0\n",
    "total_quote_count = 0\n",
    "\n",
    "for i, tweet_id, urls, retweet_count, quote_count in recent_tweet_df[[\"datastore_id\", \"urls\", \"retweet_count\", \"quote_count\"]].itertuples():\n",
    "    has_relevant_url = False\n",
    "    for url in urls:\n",
    "        if \"twitter.com/\" not in url:\n",
    "            has_relevant_url = True\n",
    "            url_map[url][\"tweet_ids\"].add(tweet_id)\n",
    "            url_map[url][\"retweet_count\"] += retweet_count\n",
    "            url_map[url][\"quote_count\"] += quote_count\n",
    "            total_retweet_count += retweet_count\n",
    "            total_quote_count += quote_count\n",
    "    if has_relevant_url:\n",
    "        total_tweet_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of tweets with URLs: 214,666\nUnique URLs shared: 58,770\nURL share retweet count: 1,354,021\nURL share quote count: 171,010\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of tweets with URLs: {:,}\".format(total_tweet_count))\n",
    "print(\"Unique URLs shared: {:,}\".format(len(url_map.keys())))\n",
    "print(\"URL share retweet count: {:,}\".format(total_retweet_count))\n",
    "print(\"URL share quote count: {:,}\".format(total_quote_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Top URLs in the dataset:\n36770 retweets from 192 tweets - https://www.breitbart.com/2020-election/2020/11/07/republican-led-michigan-legislature-to-hold-hearings-on-election-fraud-claims/\n26685 retweets from 64 tweets - https://thefederalist.com/2020/11/08/america-wont-trust-elections-until-the-voter-fraud-is-investigated/#.X6iHcjHduyR.twitter\n26266 retweets from 199 tweets - http://djt45.co/stopfraud\n21252 retweets from 563 tweets - https://breaking911.com/u-s-postal-worker-caught-at-canadian-border-with-stolen-ballots-in-car-trunk/\n18282 retweets from 138 tweets - https://www.washingtonexaminer.com/news/lindsey-graham-possible-ballot-harvesting-in-pennsylvania-involving-25-000-nursing-home-residents\n16945 retweets from 55 tweets - https://www.houstonchronicle.com/politics/texas/article/Texas-Lt-Gov-Dan-Patrick-offers-1-million-15716973.php?utm_campaign=CMS%20Sharing%20Tools%20(Premium)&utm_source=t.co&utm_medium=referral\n15667 retweets from 3072 tweets - https://www.whitehouse.gov/presidential-actions/executive-order-imposing-certain-sanctions-event-foreign-interference-united-states-election/\n15636 retweets from 84 tweets - https://nypost.com/2020/11/11/usps-whistleblower-denies-wapo-claim-he-recanted-allegations/?utm_source=twitter_sitebuttons&utm_medium=site%20buttons&utm_campaign=site%20buttons\n14123 retweets from 15 tweets - https://www.zerohedge.com/political/30-states-computer-system-known-be-defective-tallying-votes\n13826 retweets from 206 tweets - https://townhall.com/tipsheet/bethbaumann/2020/11/04/usps-whistleblower-in-michigan-claims-higher-ups-were-engaging-in-voter-fraud-n2579501\n\nYoutube URLs in the dataset: 7,094\nTop Youtube URLs in the dataset:\n7293 retweets from 404 tweets - https://youtu.be/w7vKBiPeyz4\n3952 retweets from 25 tweets - https://youtu.be/bYTa1AMLJxY\n3204 retweets from 40 tweets - https://www.youtube.com/watch?v=96-BQaIVOpc\n2382 retweets from 406 tweets - https://youtu.be/Ztu5Y5obWPk\n1605 retweets from 141 tweets - https://youtu.be/VgMPDnWunqs\n1562 retweets from 286 tweets - https://youtu.be/96-BQaIVOpc\n1401 retweets from 205 tweets - https://youtu.be/g9_SgYJnbKo\n810 retweets from 3 tweets - https://youtu.be/V5jQBYALy0g\n740 retweets from 1 tweets - https://www.youtube.com/watch?v=fveONZpDbiw&feature=share\n722 retweets from 8 tweets - https://youtu.be/Avy8eCHYd6I\n"
     ]
    }
   ],
   "source": [
    "def top_urls_by_retweet_count(url_map, N = 10):\n",
    "    for url in heapq.nlargest(N, url_map, key=lambda x: url_map.get(x)[\"retweet_count\"]):\n",
    "        url_stats = url_map.get(url)\n",
    "        tweet_count = len(url_stats[\"tweet_ids\"])\n",
    "        retweet_count = url_stats[\"retweet_count\"]\n",
    "        print(\"{} retweets from {} tweets - {}\".format(retweet_count, tweet_count, url))\n",
    "\n",
    "def filter_url_map(url_map, pred_fn=lambda x: x):\n",
    "    return { key: url_map[key] for key in url_map.keys() if pred_fn(key) }\n",
    "\n",
    "print(\"Top URLs in the dataset:\")\n",
    "top_urls_by_retweet_count(filter_url_map(url_map))\n",
    "\n",
    "print()\n",
    "\n",
    "youtube_url_map = filter_url_map(url_map, lambda x: \"youtu.be\" in x or \"youtube\" in x)\n",
    "print(\"Youtube URLs in the dataset: {:,}\".format(len(youtube_url_map.keys())))\n",
    "print(\"Top Youtube URLs in the dataset:\")\n",
    "top_urls_by_retweet_count(youtube_url_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}