{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import json\n",
    "import time\n",
    "\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "\n",
    "from urllib.parse import urlparse\n",
    "from collections import defaultdict\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get YouTube data details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_id(url):\n",
    "    \"\"\"\n",
    "    Examples:\n",
    "    - http://youtu.be/SA2iWivDJiE\n",
    "    - http://www.youtube.com/watch?v=_oPAwA_Udwc&feature=feedu\n",
    "    - http://www.youtube.com/embed/SA2iWivDJiE\n",
    "    - http://www.youtube.com/v/SA2iWivDJiE?version=3&amp;hl=en_US\n",
    "    \"\"\"\n",
    "    o = urlparse(url)\n",
    "    if o.netloc == 'youtu.be':\n",
    "        return o.path[1:]\n",
    "    elif o.netloc in ('www.youtube.com', 'youtube.com'):\n",
    "        if o.path == '/watch':\n",
    "            id_index = o.query.index('v=')\n",
    "            return o.query[id_index+2:id_index+13]\n",
    "        elif o.path[:7] == '/embed/':\n",
    "            return o.path.split('/')[2]\n",
    "        elif o.path[:3] == '/v/':\n",
    "            return o.path.split('/')[2]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set DEVELOPER_KEY to the API key value from the APIs & auth > Registered apps\n",
    "# tab of\n",
    "#   https://cloud.google.com/console\n",
    "# Please ensure that you have enabled the YouTube Data API for your project.\n",
    "with open(\"../private/youtube\", \"r\") as r:\n",
    "  for line in r:\n",
    "    DEVELOPER_KEY = line[:-1]\n",
    "    break\n",
    "YOUTUBE_API_SERVICE_NAME = 'youtube'\n",
    "YOUTUBE_API_VERSION = 'v3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def videos_list_multiple_ids(youtube, videoids):\n",
    "  response = youtube.videos().list(\n",
    "    \n",
    "  ).execute()\n",
    "\n",
    "  return response['items']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube = build(YOUTUBE_API_SERVICE_NAME, YOUTUBE_API_VERSION,\n",
    "    developerKey=DEVELOPER_KEY)\n",
    "\n",
    "\n",
    "links = []\n",
    "videoIds = []\n",
    "batchSize = 50\n",
    "with open(\"./data_export/url_stats/16-dec/expanded_url_map.json\", \"r\") as r:\n",
    "  data = json.load(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_data = []\n",
    "videoIds = []\n",
    "for key, vv in data.items():\n",
    "  if 'url' in vv['expanded_url']:\n",
    "    v = vv['expanded_url']['url']\n",
    "  else:\n",
    "    v = key\n",
    "\n",
    "  try:\n",
    "    vid = video_id(key)\n",
    "  except:\n",
    "    vid = None\n",
    "  if vid is not None:\n",
    "    videoIds.append(vid)\n",
    "    record = {'video_id': vid}\n",
    "    record.update(vv)\n",
    "    record['url'] = v\n",
    "    youtube_data.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "videoIds = list(set(videoIds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = len(videoIds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13611"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 / 13611 processed\n",
      "100 / 13611 processed\n",
      "150 / 13611 processed\n",
      "200 / 13611 processed\n",
      "250 / 13611 processed\n",
      "300 / 13611 processed\n",
      "350 / 13611 processed\n",
      "400 / 13611 processed\n",
      "450 / 13611 processed\n",
      "500 / 13611 processed\n",
      "550 / 13611 processed\n",
      "600 / 13611 processed\n",
      "650 / 13611 processed\n",
      "700 / 13611 processed\n",
      "750 / 13611 processed\n",
      "800 / 13611 processed\n",
      "850 / 13611 processed\n",
      "900 / 13611 processed\n",
      "950 / 13611 processed\n",
      "1000 / 13611 processed\n",
      "1050 / 13611 processed\n",
      "1100 / 13611 processed\n",
      "1150 / 13611 processed\n",
      "1200 / 13611 processed\n",
      "1250 / 13611 processed\n",
      "1300 / 13611 processed\n",
      "1350 / 13611 processed\n",
      "1400 / 13611 processed\n",
      "1450 / 13611 processed\n",
      "1500 / 13611 processed\n",
      "1550 / 13611 processed\n",
      "1600 / 13611 processed\n",
      "1650 / 13611 processed\n",
      "1700 / 13611 processed\n",
      "1750 / 13611 processed\n",
      "1800 / 13611 processed\n",
      "1850 / 13611 processed\n",
      "1900 / 13611 processed\n",
      "1950 / 13611 processed\n",
      "2000 / 13611 processed\n",
      "2050 / 13611 processed\n",
      "2100 / 13611 processed\n",
      "2150 / 13611 processed\n",
      "2200 / 13611 processed\n",
      "2250 / 13611 processed\n",
      "2300 / 13611 processed\n",
      "2350 / 13611 processed\n",
      "2400 / 13611 processed\n",
      "2450 / 13611 processed\n",
      "2500 / 13611 processed\n",
      "2550 / 13611 processed\n",
      "2600 / 13611 processed\n",
      "2650 / 13611 processed\n",
      "2700 / 13611 processed\n",
      "2750 / 13611 processed\n",
      "2800 / 13611 processed\n",
      "2850 / 13611 processed\n",
      "2900 / 13611 processed\n",
      "2950 / 13611 processed\n",
      "3000 / 13611 processed\n",
      "3050 / 13611 processed\n",
      "3100 / 13611 processed\n",
      "3150 / 13611 processed\n",
      "3200 / 13611 processed\n",
      "3250 / 13611 processed\n",
      "3300 / 13611 processed\n",
      "3350 / 13611 processed\n",
      "3400 / 13611 processed\n",
      "3450 / 13611 processed\n",
      "3500 / 13611 processed\n",
      "3550 / 13611 processed\n",
      "3600 / 13611 processed\n",
      "3650 / 13611 processed\n",
      "3700 / 13611 processed\n",
      "3750 / 13611 processed\n",
      "3800 / 13611 processed\n",
      "3850 / 13611 processed\n",
      "3900 / 13611 processed\n",
      "3950 / 13611 processed\n",
      "4000 / 13611 processed\n",
      "4050 / 13611 processed\n",
      "4100 / 13611 processed\n",
      "4150 / 13611 processed\n",
      "4200 / 13611 processed\n",
      "4250 / 13611 processed\n",
      "4300 / 13611 processed\n",
      "4350 / 13611 processed\n",
      "4400 / 13611 processed\n",
      "4450 / 13611 processed\n",
      "4500 / 13611 processed\n",
      "4550 / 13611 processed\n",
      "4600 / 13611 processed\n",
      "4650 / 13611 processed\n",
      "4700 / 13611 processed\n",
      "4750 / 13611 processed\n",
      "4800 / 13611 processed\n",
      "4850 / 13611 processed\n",
      "4900 / 13611 processed\n",
      "4950 / 13611 processed\n",
      "5000 / 13611 processed\n",
      "5050 / 13611 processed\n",
      "5100 / 13611 processed\n",
      "5150 / 13611 processed\n",
      "5200 / 13611 processed\n",
      "5250 / 13611 processed\n",
      "5300 / 13611 processed\n",
      "5350 / 13611 processed\n",
      "5400 / 13611 processed\n",
      "5450 / 13611 processed\n",
      "5500 / 13611 processed\n",
      "5550 / 13611 processed\n",
      "5600 / 13611 processed\n",
      "5650 / 13611 processed\n",
      "5700 / 13611 processed\n",
      "5750 / 13611 processed\n",
      "5800 / 13611 processed\n",
      "5850 / 13611 processed\n",
      "5900 / 13611 processed\n",
      "5950 / 13611 processed\n",
      "6000 / 13611 processed\n",
      "6050 / 13611 processed\n",
      "6100 / 13611 processed\n",
      "6150 / 13611 processed\n",
      "6200 / 13611 processed\n",
      "6250 / 13611 processed\n",
      "6300 / 13611 processed\n",
      "6350 / 13611 processed\n",
      "6400 / 13611 processed\n",
      "6450 / 13611 processed\n",
      "6500 / 13611 processed\n",
      "6550 / 13611 processed\n",
      "6600 / 13611 processed\n",
      "6650 / 13611 processed\n",
      "6700 / 13611 processed\n",
      "6750 / 13611 processed\n",
      "6800 / 13611 processed\n",
      "6850 / 13611 processed\n",
      "6900 / 13611 processed\n",
      "6950 / 13611 processed\n",
      "7000 / 13611 processed\n",
      "7050 / 13611 processed\n",
      "7100 / 13611 processed\n",
      "7150 / 13611 processed\n",
      "7200 / 13611 processed\n",
      "7250 / 13611 processed\n",
      "7300 / 13611 processed\n",
      "7350 / 13611 processed\n",
      "7400 / 13611 processed\n",
      "7450 / 13611 processed\n",
      "7500 / 13611 processed\n",
      "7550 / 13611 processed\n",
      "7600 / 13611 processed\n",
      "7650 / 13611 processed\n",
      "7700 / 13611 processed\n",
      "7750 / 13611 processed\n",
      "7800 / 13611 processed\n",
      "7850 / 13611 processed\n",
      "7900 / 13611 processed\n",
      "7950 / 13611 processed\n",
      "8000 / 13611 processed\n",
      "8050 / 13611 processed\n",
      "8100 / 13611 processed\n",
      "8150 / 13611 processed\n",
      "8200 / 13611 processed\n",
      "8250 / 13611 processed\n",
      "8300 / 13611 processed\n",
      "8350 / 13611 processed\n",
      "8400 / 13611 processed\n",
      "8450 / 13611 processed\n",
      "8500 / 13611 processed\n",
      "8550 / 13611 processed\n",
      "8600 / 13611 processed\n",
      "8650 / 13611 processed\n",
      "8700 / 13611 processed\n",
      "8750 / 13611 processed\n",
      "8800 / 13611 processed\n",
      "8850 / 13611 processed\n",
      "8900 / 13611 processed\n",
      "8950 / 13611 processed\n",
      "9000 / 13611 processed\n",
      "9050 / 13611 processed\n",
      "9100 / 13611 processed\n",
      "9150 / 13611 processed\n",
      "9200 / 13611 processed\n",
      "9250 / 13611 processed\n",
      "9300 / 13611 processed\n",
      "9350 / 13611 processed\n",
      "9400 / 13611 processed\n",
      "9450 / 13611 processed\n",
      "9500 / 13611 processed\n",
      "9550 / 13611 processed\n",
      "9600 / 13611 processed\n",
      "9650 / 13611 processed\n",
      "9700 / 13611 processed\n",
      "9750 / 13611 processed\n",
      "9800 / 13611 processed\n",
      "9850 / 13611 processed\n",
      "9900 / 13611 processed\n",
      "9950 / 13611 processed\n",
      "10000 / 13611 processed\n",
      "10050 / 13611 processed\n",
      "10100 / 13611 processed\n",
      "10150 / 13611 processed\n",
      "10200 / 13611 processed\n",
      "10250 / 13611 processed\n",
      "10300 / 13611 processed\n",
      "10350 / 13611 processed\n",
      "10400 / 13611 processed\n",
      "10450 / 13611 processed\n",
      "10500 / 13611 processed\n",
      "10550 / 13611 processed\n",
      "10600 / 13611 processed\n",
      "10650 / 13611 processed\n",
      "10700 / 13611 processed\n",
      "10750 / 13611 processed\n",
      "10800 / 13611 processed\n",
      "10850 / 13611 processed\n",
      "10900 / 13611 processed\n",
      "10950 / 13611 processed\n",
      "11000 / 13611 processed\n",
      "11050 / 13611 processed\n",
      "11100 / 13611 processed\n",
      "11150 / 13611 processed\n",
      "11200 / 13611 processed\n",
      "11250 / 13611 processed\n",
      "11300 / 13611 processed\n",
      "11350 / 13611 processed\n",
      "11400 / 13611 processed\n",
      "11450 / 13611 processed\n",
      "11500 / 13611 processed\n",
      "11550 / 13611 processed\n",
      "11600 / 13611 processed\n",
      "11650 / 13611 processed\n",
      "11700 / 13611 processed\n",
      "11750 / 13611 processed\n",
      "11800 / 13611 processed\n",
      "11850 / 13611 processed\n",
      "11900 / 13611 processed\n",
      "11950 / 13611 processed\n",
      "12000 / 13611 processed\n",
      "12050 / 13611 processed\n",
      "12100 / 13611 processed\n",
      "12150 / 13611 processed\n",
      "12200 / 13611 processed\n",
      "12250 / 13611 processed\n",
      "12300 / 13611 processed\n",
      "12350 / 13611 processed\n",
      "12400 / 13611 processed\n",
      "12450 / 13611 processed\n",
      "12500 / 13611 processed\n",
      "12550 / 13611 processed\n",
      "12600 / 13611 processed\n",
      "12650 / 13611 processed\n",
      "12700 / 13611 processed\n",
      "12750 / 13611 processed\n",
      "12800 / 13611 processed\n",
      "12850 / 13611 processed\n",
      "12900 / 13611 processed\n",
      "12950 / 13611 processed\n",
      "13000 / 13611 processed\n",
      "13050 / 13611 processed\n",
      "13100 / 13611 processed\n",
      "13150 / 13611 processed\n",
      "13200 / 13611 processed\n",
      "13250 / 13611 processed\n",
      "13300 / 13611 processed\n",
      "13350 / 13611 processed\n",
      "13400 / 13611 processed\n",
      "13450 / 13611 processed\n",
      "13500 / 13611 processed\n",
      "13550 / 13611 processed\n",
      "13600 / 13611 processed\n",
      "13650 / 13611 processed\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "responses = []\n",
    "while cnt < total:\n",
    "  batch = videoIds[cnt:cnt+batchSize]\n",
    "  cnt += batchSize\n",
    "  try:\n",
    "    video_response = youtube.videos().list(id=','.join(batch),\n",
    "                part='snippet').execute()\n",
    "    for item in video_response['items']:\n",
    "      responses.append(item)\n",
    "  except HttpError as e:\n",
    "    print('An HTTP error {} occurred:\\n{}'.format(e.resp.status, e.content))\n",
    "    if e.resp.status == 403:\n",
    "      cnt -= batchSize\n",
    "      time.sleep(3600* 12) # Sleep for one hour if hits rate limit \n",
    "      print('Hits rate limit, sleep for one hour.')\n",
    "  print(\"{} / {} processed\".format(cnt, total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data_export/url_stats/16-dec/youtube_data_details.json\", \"w\") as w:\n",
    "  for response in responses:\n",
    "    w.write(json.dumps(response) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top URLs in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data_export/url_stats/16-dec/all_urls.json\", \"r\") as r:\n",
    "  urls_meta = json.load(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_map = defaultdict(lambda: {\n",
    "    \"tweet_ids\": set(),\n",
    "    \"aggregated_retweet_count\": 0,\n",
    "    \"aggregated_quote_count\": 0,\n",
    "})\n",
    "\n",
    "total_tweet_count = 0\n",
    "total_retweet_count = 0\n",
    "total_quote_count = 0\n",
    "\n",
    "for key, vv in data.items():\n",
    "  if 'url' in vv['expanded_url']:\n",
    "    v = vv['expanded_url']['url']\n",
    "    urls_map[v]['domain'] = vv['expanded_url']['domain']['domain']\n",
    "  else:\n",
    "    v = key\n",
    "    urls_map[v]['domain'] = 'URL NOT AVAILABLE'\n",
    "\n",
    "  urls_map[v]['tweet_ids'] = (set(urls_map[v]['tweet_ids']) | set(urls_meta[key]['tweet_ids']))\n",
    "  urls_map[v]['aggregated_retweet_count'] += urls_meta[key]['aggregated_retweet_count']\n",
    "  urls_map[v]['aggregated_quote_count'] += urls_meta[key]['aggregated_quote_count']\n",
    "  total_retweet_count += urls_meta[key]['aggregated_retweet_count']\n",
    "  total_quote_count += urls_meta[key]['aggregated_quote_count']\n",
    "  total_tweet_count += len(urls_meta[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top URLs in the dataset:\n",
      "49638 retweets from 22106 tweets - https://www.whitehouse.gov/presidential-actions/executive-order-imposing-certain-sanctions-event-foreign-interference-united-states-election/\n",
      "46781 retweets from 603 tweets - https://www.breitbart.com/2020-election/2020/11/23/poll-79-of-trump-voters-believe-election-was-stolen-through-illegal-voting-and-fraud/\n",
      "41078 retweets from 264 tweets - https://www.foxnews.com/opinion/tucker-carlson-2020-presidential-election-voter-fraud-dead-voters.amp\n",
      "39154 retweets from 776 tweets - https://www.breitbart.com/2020-election/2020/11/19/rudy-giuliani-the-case-for-election-fraud-being-made-by-american-patriots-in-both-parties/\n",
      "36201 retweets from 195 tweets - https://www.breitbart.com/2020-election/2020/11/07/republican-led-michigan-legislature-to-hold-hearings-on-election-fraud-claims/\n",
      "32156 retweets from 334 tweets - https://www.breitbart.com/2020-election/2020/11/17/california-2-charged-with-voter-fraud-allegedly-submitted-thousands-of-applications-on-behalf-of-homeless/\n",
      "26816 retweets from 911 tweets - https://defendyourballot.formstack.com/forms/voter_fraud?utm_source=graphic\n",
      "26432 retweets from 1601 tweets - https://www.lawofficer.com/michigan-state-police-arrest-democratic-official-six-felony-charges-election-fraud/\n",
      "25969 retweets from 65 tweets - https://thefederalist.com/2020/11/08/america-wont-trust-elections-until-the-voter-fraud-is-investigated/#.X6iHcjHduyR.twitter\n",
      "24685 retweets from 255 tweets - https://www.breitbart.com/politics/2020/11/30/donald-trump-calls-in-to-arizona-voter-fraud-hearing-were-fighting-back/\n"
     ]
    }
   ],
   "source": [
    "def top_urls_by_retweet_count(url_map, N = 10):\n",
    "    for url in heapq.nlargest(N, url_map, key=lambda x: url_map.get(x)[\"aggregated_retweet_count\"]):\n",
    "        url_stats = url_map.get(url)\n",
    "        tweet_count = len(url_stats[\"tweet_ids\"])\n",
    "        retweet_count = url_stats[\"aggregated_retweet_count\"]\n",
    "        print(\"{} retweets from {} tweets - {}\".format(retweet_count, tweet_count, url))\n",
    "\n",
    "def transform_url_map(url_map, filter_fn=lambda x: x, map_key=lambda x: x):\n",
    "    new_map = {}\n",
    "    for key, val in url_map.items():\n",
    "        if filter_fn(key):\n",
    "            mapped_key = map_key(key)\n",
    "            if (mapped_key in new_map):\n",
    "                existing_entry = new_map[mapped_key]\n",
    "                existing_entry[\"tweet_ids\"].update(val[\"tweet_ids\"])\n",
    "                existing_entry[\"aggregated_retweet_count\"] += val[\"aggregated_retweet_count\"]\n",
    "                existing_entry[\"aggregated_quote_count\"] += val[\"aggregated_quote_count\"]\n",
    "                new_map[mapped_key] = existing_entry\n",
    "            else:\n",
    "                new_map[mapped_key] = val.copy()\n",
    "\n",
    "    return new_map\n",
    "\n",
    "print(\"Top URLs in the dataset:\")\n",
    "top_urls_by_retweet_count(urls_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets with URLs (excluding twitter.com URLs): 465,192\n",
      "Unique URLs shared: 138,970\n",
      "URL share retweet count: 2,847,863\n",
      "URL share quote count: 334,915\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of tweets with URLs (excluding twitter.com URLs): {:,}\".format(total_tweet_count))\n",
    "print(\"Unique URLs shared: {:,}\".format(len(urls_map.keys())))\n",
    "print(\"URL share retweet count: {:,}\".format(total_retweet_count))\n",
    "print(\"URL share quote count: {:,}\".format(total_quote_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top Domains in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique domains in the dataset: 9,650\n",
      "Top domains in the dataset:\n",
      "211496 retweets from 10828 tweets - breitbart\n",
      "149806 retweets from 2618 tweets - pscp\n",
      "130059 retweets from 91838 tweets - google\n",
      "105188 retweets from 23010 tweets - thegatewaypundit\n",
      "99581 retweets from 3500 tweets - justthenews\n",
      "97132 retweets from 5351 tweets - thefederalist\n",
      "92837 retweets from 18105 tweets - theepochtimes\n",
      "90845 retweets from 9429 tweets - foxnews\n",
      "73073 retweets from 4460 tweets - oann\n",
      "53863 retweets from 16290 tweets - rumble\n"
     ]
    }
   ],
   "source": [
    "def map_to_domain(url):\n",
    "  return urls_map[url]['domain']\n",
    "\n",
    "domain_url_map = transform_url_map(urls_map, map_key=map_to_domain)\n",
    "print(\"Unique domains in the dataset: {:,}\".format(len(domain_url_map.keys())))\n",
    "print(\"Top domains in the dataset:\")\n",
    "\n",
    "top_urls_by_retweet_count(domain_url_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top YouTube URLs in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_urls = {}\n",
    "for yturl in youtube_data:\n",
    "  youtube_urls[yturl['url']] = yturl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17319"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(youtube_urls.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique Youtube URLs in the dataset: 13,611\n",
      "Top Youtube IDs in the dataset:\n",
      "13094 retweets from 25 tweets - LPdD8Cd5PGI\n",
      "11909 retweets from 93 tweets - psGpIuNh_dU\n",
      "7271 retweets from 436 tweets - w7vKBiPeyz4\n",
      "5204 retweets from 115 tweets - QNN9I0xxZRE\n",
      "4739 retweets from 337 tweets - 96-BQaIVOpc\n",
      "3819 retweets from 32 tweets - bYTa1AMLJxY\n",
      "2465 retweets from 675 tweets - Ztu5Y5obWPk\n",
      "2260 retweets from 1467 tweets - p2MkvWh7poY\n",
      "1605 retweets from 150 tweets - VgMPDnWunqs\n",
      "1406 retweets from 223 tweets - g9_SgYJnbKo\n"
     ]
    }
   ],
   "source": [
    "def detect_youtube_url(url):\n",
    "    return url in youtube_urls\n",
    "\n",
    "def normalize_youtube_url(url):\n",
    "    return youtube_urls[url]['video_id']\n",
    "\n",
    "youtube_url_map = transform_url_map(\n",
    "    urls_map, \n",
    "    filter_fn=detect_youtube_url,\n",
    "    map_key=normalize_youtube_url\n",
    ")\n",
    "\n",
    "print()\n",
    "print(\"Unique Youtube URLs in the dataset: {:,}\".format(len(youtube_url_map.keys())))\n",
    "print(\"Top Youtube IDs in the dataset:\")\n",
    "top_urls_by_retweet_count(youtube_url_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt_details = {}\n",
    "for res in responses:\n",
    "  yt_details[res['id']] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique Youtube URLs in the dataset: 5,086\n",
      "Top Youtube channels in the dataset:\n",
      "13404 retweets from 426 tweets - Gateway Pundit\n",
      "12238 retweets from 706 tweets - Precinct 13\n",
      "8567 retweets from 2543 tweets - Project Veritas\n",
      "8058 retweets from 543 tweets - AWK NEWS\n",
      "6274 retweets from 82470 tweets - One America News Network\n",
      "5549 retweets from 1141 tweets - StevenCrowder\n",
      "5205 retweets from 120 tweets - Destiny Image\n",
      "5168 retweets from 8192 tweets - None\n",
      "3821 retweets from 67 tweets - ignant hunter\n",
      "3636 retweets from 2819 tweets - Right Side Broadcasting Network\n"
     ]
    }
   ],
   "source": [
    "def detect_youtube_url(url):\n",
    "    return url in youtube_urls\n",
    "\n",
    "def get_channel_name(url):\n",
    "    if youtube_urls[url]['video_id'] not in yt_details:\n",
    "      return None\n",
    "    if 'channelTitle' in yt_details[youtube_urls[url]['video_id']]['snippet']:\n",
    "        return yt_details[youtube_urls[url]['video_id']]['snippet']['channelTitle']\n",
    "    return None\n",
    "\n",
    "youtube_url_map = transform_url_map(\n",
    "    urls_map, \n",
    "    filter_fn=detect_youtube_url,\n",
    "    map_key=get_channel_name\n",
    ")\n",
    "\n",
    "print()\n",
    "print(\"Unique Youtube URLs in the dataset: {:,}\".format(len(youtube_url_map.keys())))\n",
    "print(\"Top Youtube channels in the dataset:\")\n",
    "top_urls_by_retweet_count(youtube_url_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}