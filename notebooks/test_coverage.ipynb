{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('voter-fraud': conda)",
   "metadata": {
    "interpreter": {
     "hash": "a0f90dcbb54bea4e60f894f8fd1d686cc0f74395b4029405cc9f13e0b975e641"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resolve paths from root project directory\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import numpy as np\n",
    "from data_tools import load_parsed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading 2696807 json lines\n",
      "(4%): 100000 lines in ../data/14-nov/parsed_tweets.json processed (1.5652921199798584 sec)\n",
      "(7%): 200000 lines in ../data/14-nov/parsed_tweets.json processed (1.6202399730682373 sec)\n",
      "(11%): 300000 lines in ../data/14-nov/parsed_tweets.json processed (1.5936200618743896 sec)\n",
      "(15%): 400000 lines in ../data/14-nov/parsed_tweets.json processed (1.4874870777130127 sec)\n",
      "(19%): 500000 lines in ../data/14-nov/parsed_tweets.json processed (1.616062879562378 sec)\n",
      "(22%): 600000 lines in ../data/14-nov/parsed_tweets.json processed (1.5352709293365479 sec)\n",
      "(26%): 700000 lines in ../data/14-nov/parsed_tweets.json processed (1.5981290340423584 sec)\n",
      "(30%): 800000 lines in ../data/14-nov/parsed_tweets.json processed (9.876200914382935 sec)\n",
      "(33%): 900000 lines in ../data/14-nov/parsed_tweets.json processed (1.6165392398834229 sec)\n",
      "(37%): 1000000 lines in ../data/14-nov/parsed_tweets.json processed (1.50541090965271 sec)\n",
      "(41%): 1100000 lines in ../data/14-nov/parsed_tweets.json processed (1.4394209384918213 sec)\n",
      "(44%): 1200000 lines in ../data/14-nov/parsed_tweets.json processed (1.4614269733428955 sec)\n",
      "(48%): 1300000 lines in ../data/14-nov/parsed_tweets.json processed (1.375126838684082 sec)\n",
      "(52%): 1400000 lines in ../data/14-nov/parsed_tweets.json processed (1.367414951324463 sec)\n",
      "(56%): 1500000 lines in ../data/14-nov/parsed_tweets.json processed (1.349323034286499 sec)\n",
      "(59%): 1600000 lines in ../data/14-nov/parsed_tweets.json processed (10.264852046966553 sec)\n",
      "(63%): 1700000 lines in ../data/14-nov/parsed_tweets.json processed (1.386080026626587 sec)\n",
      "(67%): 1800000 lines in ../data/14-nov/parsed_tweets.json processed (1.3986351490020752 sec)\n",
      "(70%): 1900000 lines in ../data/14-nov/parsed_tweets.json processed (1.5828211307525635 sec)\n",
      "(74%): 2000000 lines in ../data/14-nov/parsed_tweets.json processed (1.5199570655822754 sec)\n",
      "(78%): 2100000 lines in ../data/14-nov/parsed_tweets.json processed (1.4805262088775635 sec)\n",
      "(82%): 2200000 lines in ../data/14-nov/parsed_tweets.json processed (1.479856014251709 sec)\n",
      "(85%): 2300000 lines in ../data/14-nov/parsed_tweets.json processed (1.4295551776885986 sec)\n",
      "(89%): 2400000 lines in ../data/14-nov/parsed_tweets.json processed (1.5398507118225098 sec)\n",
      "(93%): 2500000 lines in ../data/14-nov/parsed_tweets.json processed (1.5239639282226562 sec)\n",
      "(96%): 2600000 lines in ../data/14-nov/parsed_tweets.json processed (12.75105619430542 sec)\n",
      "Done loading ../data/14-nov/parsed_tweets.json\n",
      "2696807 lines in ../data/14-nov/parsed_tweets.json processed (68.68100190162659 sec)\n",
      "Loading 8044982 json lines\n",
      "(1%): 100000 lines in ../data/14-nov/parsed_retweets.json processed (0.33777308464050293 sec)\n",
      "(2%): 200000 lines in ../data/14-nov/parsed_retweets.json processed (0.32012104988098145 sec)\n",
      "(4%): 300000 lines in ../data/14-nov/parsed_retweets.json processed (0.31643199920654297 sec)\n",
      "(5%): 400000 lines in ../data/14-nov/parsed_retweets.json processed (0.31439781188964844 sec)\n",
      "(6%): 500000 lines in ../data/14-nov/parsed_retweets.json processed (0.3425462245941162 sec)\n",
      "(7%): 600000 lines in ../data/14-nov/parsed_retweets.json processed (0.3109121322631836 sec)\n",
      "(9%): 700000 lines in ../data/14-nov/parsed_retweets.json processed (0.2999579906463623 sec)\n",
      "(10%): 800000 lines in ../data/14-nov/parsed_retweets.json processed (0.30640101432800293 sec)\n",
      "(11%): 900000 lines in ../data/14-nov/parsed_retweets.json processed (0.32242584228515625 sec)\n",
      "(12%): 1000000 lines in ../data/14-nov/parsed_retweets.json processed (0.3696939945220947 sec)\n",
      "(14%): 1100000 lines in ../data/14-nov/parsed_retweets.json processed (0.37039780616760254 sec)\n",
      "(15%): 1200000 lines in ../data/14-nov/parsed_retweets.json processed (0.37250804901123047 sec)\n",
      "(16%): 1300000 lines in ../data/14-nov/parsed_retweets.json processed (0.35072803497314453 sec)\n",
      "(17%): 1400000 lines in ../data/14-nov/parsed_retweets.json processed (0.3741021156311035 sec)\n",
      "(19%): 1500000 lines in ../data/14-nov/parsed_retweets.json processed (0.36109113693237305 sec)\n",
      "(20%): 1600000 lines in ../data/14-nov/parsed_retweets.json processed (0.34888505935668945 sec)\n",
      "(21%): 1700000 lines in ../data/14-nov/parsed_retweets.json processed (0.3801991939544678 sec)\n",
      "(22%): 1800000 lines in ../data/14-nov/parsed_retweets.json processed (0.36443281173706055 sec)\n",
      "(24%): 1900000 lines in ../data/14-nov/parsed_retweets.json processed (0.3699531555175781 sec)\n",
      "(25%): 2000000 lines in ../data/14-nov/parsed_retweets.json processed (0.36354494094848633 sec)\n",
      "(26%): 2100000 lines in ../data/14-nov/parsed_retweets.json processed (0.3631622791290283 sec)\n",
      "(27%): 2200000 lines in ../data/14-nov/parsed_retweets.json processed (0.34555697441101074 sec)\n",
      "(29%): 2300000 lines in ../data/14-nov/parsed_retweets.json processed (0.3364889621734619 sec)\n",
      "(30%): 2400000 lines in ../data/14-nov/parsed_retweets.json processed (0.315295934677124 sec)\n",
      "(31%): 2500000 lines in ../data/14-nov/parsed_retweets.json processed (0.31763601303100586 sec)\n",
      "(32%): 2600000 lines in ../data/14-nov/parsed_retweets.json processed (0.3383910655975342 sec)\n",
      "(34%): 2700000 lines in ../data/14-nov/parsed_retweets.json processed (0.3448939323425293 sec)\n",
      "(35%): 2800000 lines in ../data/14-nov/parsed_retweets.json processed (0.369326114654541 sec)\n",
      "(36%): 2900000 lines in ../data/14-nov/parsed_retweets.json processed (0.3680880069732666 sec)\n",
      "(37%): 3000000 lines in ../data/14-nov/parsed_retweets.json processed (0.37651586532592773 sec)\n",
      "(39%): 3100000 lines in ../data/14-nov/parsed_retweets.json processed (0.3590059280395508 sec)\n",
      "(40%): 3200000 lines in ../data/14-nov/parsed_retweets.json processed (0.39644503593444824 sec)\n",
      "(41%): 3300000 lines in ../data/14-nov/parsed_retweets.json processed (0.3628542423248291 sec)\n",
      "(42%): 3400000 lines in ../data/14-nov/parsed_retweets.json processed (0.36627817153930664 sec)\n",
      "(44%): 3500000 lines in ../data/14-nov/parsed_retweets.json processed (0.35159993171691895 sec)\n",
      "(45%): 3600000 lines in ../data/14-nov/parsed_retweets.json processed (0.3568739891052246 sec)\n",
      "(46%): 3700000 lines in ../data/14-nov/parsed_retweets.json processed (0.3433878421783447 sec)\n",
      "(47%): 3800000 lines in ../data/14-nov/parsed_retweets.json processed (0.34287095069885254 sec)\n",
      "(48%): 3900000 lines in ../data/14-nov/parsed_retweets.json processed (0.34134411811828613 sec)\n",
      "(50%): 4000000 lines in ../data/14-nov/parsed_retweets.json processed (0.3613569736480713 sec)\n",
      "(51%): 4100000 lines in ../data/14-nov/parsed_retweets.json processed (0.34656572341918945 sec)\n",
      "(52%): 4200000 lines in ../data/14-nov/parsed_retweets.json processed (0.3537619113922119 sec)\n",
      "(53%): 4300000 lines in ../data/14-nov/parsed_retweets.json processed (0.3574798107147217 sec)\n",
      "(55%): 4400000 lines in ../data/14-nov/parsed_retweets.json processed (0.35920095443725586 sec)\n",
      "(56%): 4500000 lines in ../data/14-nov/parsed_retweets.json processed (0.34594297409057617 sec)\n",
      "(57%): 4600000 lines in ../data/14-nov/parsed_retweets.json processed (0.3644752502441406 sec)\n",
      "(58%): 4700000 lines in ../data/14-nov/parsed_retweets.json processed (0.3326761722564697 sec)\n",
      "(60%): 4800000 lines in ../data/14-nov/parsed_retweets.json processed (0.3392457962036133 sec)\n",
      "(61%): 4900000 lines in ../data/14-nov/parsed_retweets.json processed (0.33843517303466797 sec)\n",
      "(62%): 5000000 lines in ../data/14-nov/parsed_retweets.json processed (0.32337188720703125 sec)\n",
      "(63%): 5100000 lines in ../data/14-nov/parsed_retweets.json processed (0.3531208038330078 sec)\n",
      "(65%): 5200000 lines in ../data/14-nov/parsed_retweets.json processed (0.3419380187988281 sec)\n",
      "(66%): 5300000 lines in ../data/14-nov/parsed_retweets.json processed (0.32294607162475586 sec)\n",
      "(67%): 5400000 lines in ../data/14-nov/parsed_retweets.json processed (0.30702996253967285 sec)\n",
      "(68%): 5500000 lines in ../data/14-nov/parsed_retweets.json processed (0.32665586471557617 sec)\n",
      "(70%): 5600000 lines in ../data/14-nov/parsed_retweets.json processed (0.30675601959228516 sec)\n",
      "(71%): 5700000 lines in ../data/14-nov/parsed_retweets.json processed (0.31806087493896484 sec)\n",
      "(72%): 5800000 lines in ../data/14-nov/parsed_retweets.json processed (0.317979097366333 sec)\n",
      "(73%): 5900000 lines in ../data/14-nov/parsed_retweets.json processed (0.3245561122894287 sec)\n",
      "(75%): 6000000 lines in ../data/14-nov/parsed_retweets.json processed (0.31563901901245117 sec)\n",
      "(76%): 6100000 lines in ../data/14-nov/parsed_retweets.json processed (0.3378629684448242 sec)\n",
      "(77%): 6200000 lines in ../data/14-nov/parsed_retweets.json processed (0.3069460391998291 sec)\n",
      "(78%): 6300000 lines in ../data/14-nov/parsed_retweets.json processed (0.3025479316711426 sec)\n",
      "(80%): 6400000 lines in ../data/14-nov/parsed_retweets.json processed (0.32007312774658203 sec)\n",
      "(81%): 6500000 lines in ../data/14-nov/parsed_retweets.json processed (0.3178539276123047 sec)\n",
      "(82%): 6600000 lines in ../data/14-nov/parsed_retweets.json processed (0.3024179935455322 sec)\n",
      "(83%): 6700000 lines in ../data/14-nov/parsed_retweets.json processed (0.32718491554260254 sec)\n",
      "(85%): 6800000 lines in ../data/14-nov/parsed_retweets.json processed (0.3907959461212158 sec)\n",
      "(86%): 6900000 lines in ../data/14-nov/parsed_retweets.json processed (0.40442490577697754 sec)\n",
      "(87%): 7000000 lines in ../data/14-nov/parsed_retweets.json processed (0.42754387855529785 sec)\n",
      "(88%): 7100000 lines in ../data/14-nov/parsed_retweets.json processed (0.36966705322265625 sec)\n",
      "(89%): 7200000 lines in ../data/14-nov/parsed_retweets.json processed (0.3378610610961914 sec)\n",
      "(91%): 7300000 lines in ../data/14-nov/parsed_retweets.json processed (0.35437893867492676 sec)\n",
      "(92%): 7400000 lines in ../data/14-nov/parsed_retweets.json processed (0.34161901473999023 sec)\n",
      "(93%): 7500000 lines in ../data/14-nov/parsed_retweets.json processed (0.35356998443603516 sec)\n",
      "(94%): 7600000 lines in ../data/14-nov/parsed_retweets.json processed (0.3389701843261719 sec)\n",
      "(96%): 7700000 lines in ../data/14-nov/parsed_retweets.json processed (0.30904507637023926 sec)\n",
      "(97%): 7800000 lines in ../data/14-nov/parsed_retweets.json processed (0.36089396476745605 sec)\n",
      "(98%): 7900000 lines in ../data/14-nov/parsed_retweets.json processed (0.36214184761047363 sec)\n",
      "(99%): 8000000 lines in ../data/14-nov/parsed_retweets.json processed (0.3535499572753906 sec)\n",
      "Done loading ../data/14-nov/parsed_retweets.json\n",
      "8044982 lines in ../data/14-nov/parsed_retweets.json processed (27.740723848342896 sec)\n"
     ]
    }
   ],
   "source": [
    "# Load our tweets\n",
    "cast_cols = {\n",
    "    \"tweet_count\": \"int32\",\n",
    "    \"quote_count\": \"int32\" \n",
    "}\n",
    "\n",
    "from data_tools import load_crawled_terms\n",
    "crawled_terms = load_crawled_terms(\"../keywords-3nov.txt\")\n",
    "\n",
    "for term in crawled_terms:\n",
    "    cast_cols[term.lower()] = \"Sparse[int8]\"\n",
    "\n",
    "tweet_df = load_parsed_data('../data/14-nov/parsed_tweets.json', exclude_cols={\n",
    "    \"cleaned_text\", \n",
    "    \"entities\",\n",
    "    \"replyTo\",\n",
    "    \"replyTo_user\",\n",
    "    \"text\", \n",
    "    \"last_retweeted\", \n",
    "    \"place\", \n",
    "    \"processed\",\n",
    "    \"media\", \n",
    "    \"isDeleted\"\n",
    "}, cast_cols=cast_cols, verbose=True, index_col=\"datastore_id\")\n",
    "retweet_df = load_parsed_data('../data/14-nov/parsed_retweets.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Processing us-presidential-tweet-id-2020-11-06-13.jsonl.gz\n",
      "Processed 25000 lines (7109 tweets / 17891 retweets)\n",
      "Processed 50000 lines (14215 tweets / 35785 retweets)\n",
      "Processed 75000 lines (21543 tweets / 53457 retweets)\n",
      "Processed 100000 lines (28607 tweets / 71393 retweets)\n",
      "Processed 125000 lines (36018 tweets / 88982 retweets)\n",
      "Processed 150000 lines (43456 tweets / 106544 retweets)\n",
      "Processed 175000 lines (51474 tweets / 123526 retweets)\n",
      "Total crawled terms found: 1777 tweets / 6782 retweets\n",
      "Processing us-presidential-tweet-id-2020-11-06-07.jsonl.gz\n",
      "Processed 200000 lines (59856 tweets / 140144 retweets)\n",
      "Processed 225000 lines (66951 tweets / 158049 retweets)\n",
      "Processed 250000 lines (74068 tweets / 175932 retweets)\n",
      "Processed 275000 lines (80356 tweets / 194644 retweets)\n",
      "Processed 300000 lines (86519 tweets / 213481 retweets)\n",
      "Processed 325000 lines (93934 tweets / 231066 retweets)\n",
      "Processed 350000 lines (101501 tweets / 248499 retweets)\n",
      "Processed 375000 lines (109277 tweets / 265723 retweets)\n",
      "Processed 400000 lines (117128 tweets / 282872 retweets)\n",
      "Total crawled terms found: 3024 tweets / 11514 retweets\n",
      "Processing us-presidential-tweet-id-2020-11-06-06.jsonl.gz\n",
      "Processed 425000 lines (124463 tweets / 300537 retweets)\n",
      "Processed 450000 lines (131463 tweets / 318537 retweets)\n",
      "Processed 475000 lines (138510 tweets / 336490 retweets)\n",
      "Processed 500000 lines (145523 tweets / 354477 retweets)\n",
      "Processed 525000 lines (152508 tweets / 372492 retweets)\n",
      "Processed 550000 lines (159584 tweets / 390416 retweets)\n",
      "Processed 575000 lines (166736 tweets / 408264 retweets)\n",
      "Total crawled terms found: 4527 tweets / 17471 retweets\n",
      "Processing us-presidential-tweet-id-2020-11-06-12.jsonl.gz\n",
      "Processed 600000 lines (174227 tweets / 425773 retweets)\n",
      "Processed 625000 lines (181719 tweets / 443281 retweets)\n",
      "Processed 650000 lines (189169 tweets / 460831 retweets)\n",
      "Processed 675000 lines (196122 tweets / 478878 retweets)\n",
      "Processed 700000 lines (202995 tweets / 497005 retweets)\n",
      "Processed 725000 lines (209983 tweets / 515017 retweets)\n",
      "Processed 750000 lines (217031 tweets / 532969 retweets)\n",
      "Processed 775000 lines (223897 tweets / 551103 retweets)\n",
      "Total crawled terms found: 6199 tweets / 24572 retweets\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import json\n",
    "\n",
    "hydrated_tweet_dir = './coverage-test/2020-11-06/'\n",
    "hydrated_tweets = [\n",
    "    'us-presidential-tweet-id-2020-11-06-13.jsonl.gz',\n",
    "    'us-presidential-tweet-id-2020-11-06-07.jsonl.gz',\n",
    "    'us-presidential-tweet-id-2020-11-06-06.jsonl.gz',\n",
    "    'us-presidential-tweet-id-2020-11-06-12.jsonl.gz'\n",
    "]\n",
    "\n",
    "line_count = 0\n",
    "tweet_count = 0\n",
    "retweet_count = 0\n",
    "matching_tweets = []\n",
    "matching_retweets = []\n",
    "\n",
    "for filename in hydrated_tweets:\n",
    "    print(\"Processing {}\".format(filename))\n",
    "    with gzip.open(hydrated_tweet_dir + filename) as zipfile:\n",
    "        for line in zipfile:\n",
    "            tweet = json.loads(line)\n",
    "            if 'retweeted_status' in tweet:\n",
    "                retweet_count += 1\n",
    "            else: \n",
    "                tweet_count += 1\n",
    "            for term in crawled_terms:\n",
    "                if (term.lower() in tweet['full_text'].lower()):\n",
    "                    if 'retweeted_status' in tweet:\n",
    "                        matching_retweets.append(tweet)\n",
    "                    else: \n",
    "                        matching_tweets.append(tweet)\n",
    "                    break\n",
    "            line_count += 1\n",
    "            if (line_count % 25000 == 0):\n",
    "                print(\"Processed {} lines ({} tweets / {} retweets)\".format(line_count, tweet_count, retweet_count))\n",
    "    print(\"Total crawled terms found: {} tweets / {} retweets\".format(len(matching_tweets), len(matching_retweets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# build lookup table for retweets\n",
    "from collections import defaultdict \n",
    "retweets_by_user = defaultdict(lambda: set())\n",
    "\n",
    "for retweet in retweet_df.itertuples():\n",
    "    retweets_by_user[retweet.user].add(retweet.retweeted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "missing_tweets = []\n",
    "missing_retweets = []\n",
    "\n",
    "for tweet in matching_tweets:\n",
    "    if (str(tweet['id']) not in tweet_df.index):\n",
    "        missing_tweets.append(tweet)\n",
    "\n",
    "for retweet in matching_retweets:\n",
    "    retweeted_tweet = retweet['retweeted_status']\n",
    "    user_id = str(retweet['user']['id'])\n",
    "    if (str(retweeted_tweet['id']) not in retweets_by_user[user_id]):\n",
    "        missing_retweets.append(retweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Missing 2792/6199 tweets (45.0%)\nMissed 1694 for term: 'voter fraud'\nMissed 314 for term: '#stopthesteal'\nMissed 289 for term: '#voterfraud'\nMissed 253 for term: 'election fraud'\nMissed 83 for term: '#electionfraud'\nMissed 76 for term: 'ballot harvesting'\nMissed 64 for term: 'ballot fraud'\nMissed 39 for term: 'election interference'\nMissed 26 for term: 'democrats cheat'\nMissed 15 for term: '#electioninterference'\nMissed 14 for term: '#ballotharvesting'\nMissed 14 for term: '#cheatingdemocrats'\nMissed 10 for term: 'stolen ballots'\nMissed 10 for term: 'election tampering'\nMissed 5 for term: 'cheating democrats'\nMissed 5 for term: '#ballotfraud'\nMissed 4 for term: '#democratvoterfraud'\nMissed 2 for term: '#voterfraudisreal'\nMissed 2 for term: '#stopvoterfraud'\nMissed 1 for term: 'discarded ballots'\nMissed 1 for term: '#electiontampering'\nMissed 1 for term: 'harvest ballot'\n"
     ]
    }
   ],
   "source": [
    "def print_missing_stats(matching, missing, stats_type):\n",
    "    term_stats = defaultdict(lambda: set())\n",
    "    print(\"Missing {}/{} {} ({:,.1f}%)\".format(\n",
    "        len(missing),\n",
    "        len(matching),\n",
    "        stats_type,\n",
    "        (len(missing) / len(matching)) * 100\n",
    "    ))\n",
    "\n",
    "    for tweet in missing:\n",
    "        for term in crawled_terms:\n",
    "            if term.lower() in tweet['full_text'].lower():\n",
    "                term_stats[term.lower()].add(tweet['full_text'])\n",
    "    \n",
    "    for (term, term_set) in sorted(term_stats.items(), key=lambda x: -len(x[1])):\n",
    "        if (len(term_set) > 0):\n",
    "            print(\"Missed {} for term: '{}'\".format(\n",
    "                len(term_set),\n",
    "                term\n",
    "            ))      \n",
    "\n",
    "print_missing_stats(matching_tweets, missing_tweets, 'tweets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Missing 11424/24572 retweets (46.5%)\n",
      "Missed 1053 for term: 'voter fraud'\n",
      "Missed 171 for term: 'election fraud'\n",
      "Missed 158 for term: '#voterfraud'\n",
      "Missed 133 for term: '#stopthesteal'\n",
      "Missed 36 for term: 'ballot fraud'\n",
      "Missed 36 for term: 'ballot harvesting'\n",
      "Missed 30 for term: '#electionfraud'\n",
      "Missed 15 for term: 'election interference'\n",
      "Missed 10 for term: 'democrats cheat'\n",
      "Missed 8 for term: 'stolen ballots'\n",
      "Missed 7 for term: '#electioninterference'\n",
      "Missed 6 for term: '#ballotharvesting'\n",
      "Missed 4 for term: '#voterfraudisreal'\n",
      "Missed 4 for term: 'election tampering'\n",
      "Missed 3 for term: 'discarded ballots'\n",
      "Missed 3 for term: '#cheatingdemocrats'\n",
      "Missed 2 for term: '#ballotfraud'\n",
      "Missed 1 for term: '#mailinvoterfraud'\n",
      "Missed 1 for term: 'cheating democrats'\n",
      "Missed 1 for term: '#stopvoterfraud'\n"
     ]
    }
   ],
   "source": [
    "print_missing_stats(matching_retweets, missing_retweets, 'retweets')"
   ]
  },
  {
   "source": [
    "### Random sample of missing tweets/retweets\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-- Missing tweets --\n[1324594699265454088]: The MSM won't show you but this is why Biden never left his basement, he never needed to campaign because the election was hoax #stopthesteal #TRUMPWILLTRIUMPH #voterfraud https://t.co/5kRly10MZw\n\n[1324709102669438981]: @caseycoley5 @EricTrump No, Biden did not brag about committing voter fraud https://t.co/uSj9kMQzQ5\n\n[1324617620935593987]: VOTER FRAUD https://t.co/EWhSrhhrjk\n\n\n-- Missing retweets --\n[1324604593888702464]: RT @Wizard_Predicts: ðŸš¨BREAKING: DOJ Arrests U.S. Postal Worker Caught at Canadian Border With Stolen Ballots In Car Trunk. https://t.co/S2Zâ€¦\n\n[1324598872572891136]: RT @BuCap004: Pastor Torah Grace proves voter fraud, shares her experience and provides evidence:\n\nPart 1 https://t.co/EPzAJkvAcT\n\n[1324702635379871745]: RT @Al_Sanchino: Itâ€™s wild Trump supporters believe thereâ€™s voter fraud with 0 evidence but couldnâ€™t believe he sexually assaulted any womeâ€¦\n\n[1324707245272100864]: RT @mimzybug: Ballot harvesting, a habit of ignoring ballot fraud in the past, is what has lead criminals to expand their enterprise to theâ€¦\n\n[1324701348231671809]: RT @NVGOP: Our lawyers just sent a criminal referral to AG Barr regarding at least 3,062 instances of voter fraud. We expect that number toâ€¦\n\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"-- Missing tweets --\")\n",
    "for tweet in np.random.choice(missing_tweets, 3):\n",
    "    print(\"[{}]: {}\".format(tweet['id'], tweet['full_text']))\n",
    "    print()\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"-- Missing retweets --\")\n",
    "for retweet in np.random.choice(missing_retweets, 5):\n",
    "    print(\"[{}]: {}\".format(retweet['id'], retweet['full_text']))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}